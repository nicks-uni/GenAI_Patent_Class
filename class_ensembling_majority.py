# -------------------------------------------------------------
# Import Required Packages
# -------------------------------------------------------------
# These lines import various tools and libraries that the script will use.
import \
    os  # Provides functions for interacting with the operating system, such as reading or writing files and creating directories.
import logging  # Enables logging of events that happen when some software runs, useful for debugging and monitoring.
import warnings  # Used to control warning messages generated by the code.
import \
    gc  # Provides functions to interact with the garbage collector, which helps manage memory by freeing up unused resources.

import \
    pandas as pd  # A powerful library for data manipulation and analysis, especially for working with tables of data.
import \
    numpy as np  # A library that supports large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays.
from tqdm import \
    tqdm  # Provides a progress bar for loops, making it easier to track the progress of long-running operations.
import \
    matplotlib.pyplot as plt  # A plotting library used for creating static, animated, and interactive visualizations.
import \
    seaborn as sns  # A library built on top of matplotlib that provides a higher-level interface for drawing attractive statistical graphics.

# Sklearn imports
from sklearn.model_selection import \
    StratifiedKFold  # A tool for splitting data into training and testing sets while maintaining the percentage of samples for each class.
from sklearn.metrics import (
    accuracy_score,  # Measures the proportion of correct predictions out of all predictions made.
    roc_auc_score,  # Measures the ability of the model to distinguish between classes.
    precision_score,  # Measures the accuracy of positive predictions.
    recall_score,  # Measures the ability of the model to find all positive instances.
    f1_score,  # The harmonic mean of precision and recall, providing a balance between the two.
    confusion_matrix,  # Summarizes the performance of a classification algorithm by displaying true vs. predicted labels.
)
from sklearn.svm import \
    SVC  # Support Vector Classifier, a type of machine learning model used for classification tasks.
from sklearn.ensemble import \
    RandomForestClassifier  # An ensemble model that builds multiple decision trees and merges their results for better accuracy.
from sklearn.feature_extraction.text import \
    TfidfVectorizer  # Converts a collection of raw documents to a matrix of TF-IDF features.

# Text processing imports
from nltk.tokenize import word_tokenize  # Splits sentences into words (tokens) using Natural Language Toolkit (NLTK).
from spacy.lang.en import STOP_WORDS  # A list of common English stop words (e.g., 'the', 'and') provided by spaCy.
import spacy  # A library for advanced Natural Language Processing in Python.

# For LLMs
from simpletransformers.classification import \
    ClassificationModel  # Simplifies the use of transformer models for classification tasks.
import torch  # A deep learning library that provides tensor computations and automatic differentiation.
import joblib  # Provides tools for saving and loading Python objects efficiently.

# Suppress warnings and set logging level to ERROR to reduce output clutter
warnings.filterwarnings("ignore")  # This line tells Python to ignore all warning messages, keeping the output clean.
logging.basicConfig(level=logging.ERROR)  # Sets the logging level to ERROR, so only error messages are logged.
transformers_logger = logging.getLogger("transformers")  # Gets the logger for the 'transformers' library.
transformers_logger.setLevel(logging.ERROR)  # Sets the 'transformers' logger to only show ERROR level messages.

# Check if CUDA is available (for GPU acceleration)
use_cuda = torch.cuda.is_available()  # Checks if a CUDA-compatible GPU is available for faster computations.


def simple_tokenizer(text):
    """
    A simple tokenizer function that converts text to lowercase, splits it into words,
    and removes any non-alphanumeric tokens.

    Parameters:
    - text (str): The text to tokenize.

    Returns:
    - List[str]: A list of cleaned, alphanumeric tokens.
    """
    tokens = word_tokenize(text.lower())  # Converts text to lowercase and splits into words.
    return [token for token in tokens if token.isalnum()]  # Keeps only alphanumeric tokens.


# -------------------------------------------------------------
# Define the PatentEnsembleClassifier Class
# -------------------------------------------------------------
class PatentEnsembleClassifier:
    def __init__(self, data_path, anti_seed_path, delimiter):
        """
        Initialize the PatentEnsembleClassifier with data paths and configuration.

        Parameters:
        - data_path (str): Path to the main training data CSV file.
        - anti_seed_path (str): Path to the anti-seed data CSV file.
        - delimiter (str): Character used to separate values in the CSV files (e.g., ',', ';').
        """
        self.data_path = data_path  # Stores the path to the main training data.
        self.anti_seed_path = anti_seed_path  # Stores the path to the anti-seed data.
        self.delimiter = delimiter  # Stores the delimiter used in the CSV files.
        self.data = None  # Placeholder for the combined dataset.
        self.IDs = None  # Placeholder for patent IDs.
        self.texts = None  # Placeholder for patent abstracts.
        self.labels = None  # Placeholder for labels indicating GenAI patents (1) or not (0).
        self.total_entries = None  # Placeholder for the total number of patents.
        self.total_ratio = None  # Placeholder for the ratio of GenAI to non-GenAI patents.
        self.results = []  # List to store performance results of each model.
        self.classified_values = []  # List to store individual classification results (actual vs. predicted).
        self.classified_values_p = []  # List to store predicted probabilities, if available.
        self.metrics = ["Accuracy", "AUC", "Precision", "Recall", "F1"]  # List of performance metrics to evaluate.
        self.results_table = None  # Placeholder for the table of results.

        # For BOW
        self.vectorizer = None  # Placeholder for the TF-IDF vectorizer for Bag-of-Words.
        self.text_vectors_bow = None  # Placeholder for the numerical representation of the patent abstracts using BOW.

        # For embeddings
        self.nlp = None  # Placeholder for the spaCy language model.
        self.text_vectors_embeddings = None  # Placeholder for the numerical representation of the patent abstracts using embeddings.

        # For LLMs
        self.use_cuda = use_cuda  # Indicates whether to use GPU acceleration for Large Language Models.

    def load_data(self):
        """
        Load and preprocess the training data from a CSV file.

        This function reads the CSV file containing patent data, processes it by creating a new label column
        indicating whether each patent is related to Generative AI (GenAI), and stores the processed data.
        """
        # Load CSV file with patent data
        self.data = pd.read_csv(self.data_path, delimiter=self.delimiter)  # Reads the CSV file into a pandas DataFrame.

        # Categorize: if 'Finales Resultat' >= 1, set 'label_genai' to 1, else 0
        self.data["label_genai"] = (self.data["Finales Resultat"] >= 1).astype(
            int)  # Creates a new column 'label_genai' based on the 'Finales Resultat' column.

    def load_anti_seed(self, n):
        """
        Load and integrate the anti-seed data to balance the dataset.

        Parameters:
        - n (int): Number of anti-seed entries to include in the dataset.

        This function reads additional data containing non-GenAI patents to balance the dataset, ensuring
        that there are enough non-GenAI examples for the model to learn effectively.
        """
        # Load AI patents to create an anti-seed set
        anti_seed = pd.read_csv(self.anti_seed_path,
                                delimiter=",")  # Reads the anti-seed CSV file into a pandas DataFrame.

        # Filter patents without AI content (actual == 0)
        anti_seed = anti_seed[anti_seed["actual"] == 0]  # Filters the DataFrame to include only non-GenAI patents.

        # Limit the anti-seed dataset to n patents
        anti_seed = anti_seed[:n]  # Selects the first 'n' entries from the anti-seed DataFrame.

        # Adjust columns in the anti-seed set to combine with training data
        anti_seed["label_genai"] = 0  # Sets the 'label_genai' column to 0 for all anti-seed patents (non-GenAI).

        # Unify column names
        anti_seed = anti_seed.rename(
            columns={"app number": "patent_id", "abstract": "patent_abstract"}
        )  # Renames columns to ensure consistency with the main training data.

        # Select relevant columns for merging
        anti_seed = anti_seed[["patent_id", "patent_abstract", "label_genai"]]  # Keeps only the necessary columns.

        # Combine training data with anti-seed data
        self.data = pd.concat(
            [
                self.data[["patent_id", "patent_abstract", "label_genai"]],
                anti_seed,
            ],
            ignore_index=True,
        )  # Merges the main data with the anti-seed data to create a balanced dataset.

    def prepare_data(self):
        """
        Prepare data for text classification.

        This function extracts the necessary information from the combined dataset and calculates the distribution
        of labels to understand the balance between GenAI and non-GenAI patents.
        """
        # Extract IDs, texts, and labels
        self.IDs = self.data["patent_id"].values  # Extracts patent IDs as a NumPy array.
        self.texts = self.data["patent_abstract"].tolist()  # Extracts patent abstracts as a list.
        self.labels = self.data["label_genai"].tolist()  # Extracts labels (1 or 0) as a list.

        # Calculate the distribution of label_genai
        label_counts = self.data["label_genai"].value_counts(
            normalize=True) * 100  # Calculates the percentage of each label.
        self.total_entries = len(self.data)  # Counts the total number of patents.
        self.total_ratio = f"{label_counts.get(1, 0):.0f}-{label_counts.get(0, 0):.0f}"  # Formats the ratio as "GenAI%-Non-GenAI%".

        # Output the distribution and total count
        print(f"Share of entries with '1': {label_counts.get(1, 0):.2f}%")  # Prints the percentage of GenAI patents.
        print(
            f"Share of entries with '0': {label_counts.get(0, 0):.2f}%")  # Prints the percentage of non-GenAI patents.
        print(f"1/0 Ratio: {self.total_ratio}")  # Prints the ratio of GenAI to non-GenAI patents.
        print(f"Total number of entries: {self.total_entries}")  # Prints the total number of patents.

    def preprocess_bow(self):
        """
        Prepare data for Bag-of-Words (BOW) model after cross-validation.
        This method fits the vectorizer on the entire dataset and saves it.

        Bag-of-Words is a method to convert text data into numerical data by counting the frequency of each word.
        """
        # Define model parameters for TF-IDF vectorization
        MINDF = 10  # Minimum number of documents a word must appear in to be included.
        MAXDF = 0.8  # Maximum proportion of documents a word can appear in to be included.
        MAX_FEATURES = 1200  # Maximum number of features (words) to consider.
        NGRAM_RANGE = (1, 2)  # Range of n-grams to include (e.g., single words and pairs of words).

        # Load stop words to ignore during vectorization
        stop_words = list(STOP_WORDS)  # Retrieves a list of common English stop words from spaCy.

        # Define TF-IDF vectorizer
        self.vectorizer = TfidfVectorizer(
            max_features=MAX_FEATURES,  # Limits the number of features to the top 'MAX_FEATURES'.
            max_df=MAXDF,  # Ignores words that appear in more than 'MAXDF' proportion of documents.
            min_df=MINDF,  # Ignores words that appear in fewer than 'MINDF' documents.
            stop_words=stop_words,  # Removes common stop words.
            ngram_range=NGRAM_RANGE,  # Considers both single words and pairs of words.
            tokenizer=simple_tokenizer,  # Uses the custom tokenizer defined above.
            token_pattern=None,  # Ensures compatibility with the custom tokenizer.
        )

        # Fit the vectorizer on the entire dataset
        self.vectorizer.fit(
            self.texts)  # Learns the vocabulary dictionary and inverse document frequency (IDF) from the texts.

        # Save the vectorizer for future use
        vectorizer_filename = 'Models/bow_vectorizer_final.joblib'  # Defines the filename for saving the vectorizer.
        joblib.dump(self.vectorizer, vectorizer_filename)  # Saves the vectorizer to a file.
        print(f"BOW vectorizer saved to {vectorizer_filename}")  # Confirms that the vectorizer has been saved.

        # Transform text data into TF-IDF matrix
        self.text_vectors_bow = self.vectorizer.transform(
            self.texts)  # Converts the list of abstracts into a numerical matrix.

        # Output the number of features for verification
        self.feature_names = self.vectorizer.get_feature_names_out()  # Retrieves the names of the features (words) used in the vectorization.
        print(
            f"Number of extracted features: {len(self.feature_names)}")  # Prints the total number of features extracted.

    def preprocess_embeddings(self):
        """
        Prepare data for embeddings model using spaCy.

        This function uses spaCy's word embeddings to convert each patent abstract into a numerical vector that captures its semantic meaning.
        """
        # Load spaCy and the 'en_core_web_lg' model
        try:
            self.nlp = spacy.load("en_core_web_lg")  # Attempts to load the large English language model.
        except:
            import spacy.cli  # Imports the spaCy command-line interface.
            spacy.cli.download("en_core_web_lg")  # Downloads the large English language model if not already installed.
            self.nlp = spacy.load("en_core_web_lg")  # Loads the model after downloading.

        # Convert each abstract into vector representation
        self.text_vectors_embeddings = np.array(
            [self.nlp(doc).vector for doc in tqdm(self.texts, desc="Computing embeddings")]
        )  # Uses spaCy to convert each patent abstract into a numerical vector based on word embeddings.

        # Output the dimension of the embeddings
        print(
            f"Embedding dimension: {self.text_vectors_embeddings.shape[1]}")  # Prints the size of each embedding vector.

    def train_and_evaluate_models(self):
        """
        Train and evaluate all models.

        This function sets up different machine learning models, trains them using cross-validation,
        evaluates their performance using various metrics, and stores the results for comparison.
        """
        NUM_OF_SPLITS = 5  # Number of folds for cross-validation.
        Reweight = True  # Option to manually adjust class distribution during training.

        # Convert labels to numpy array for efficient processing
        Y = np.array(self.labels)  # Array of labels (1 or 0).
        IDs = np.array(self.IDs)  # Array of patent IDs.

        # Prepare data arrays
        Texts = np.array(self.texts)  # Array of patent abstracts.
        Abstract_Vectors_BOW = self.text_vectors_bow  # Numerical representation using BOW.
        Abstract_Vectors_Embeddings = self.text_vectors_embeddings  # Numerical representation using embeddings.

        # Initialize KFold splitter
        KFoldSplitter = StratifiedKFold(n_splits=NUM_OF_SPLITS, shuffle=True,
                                        random_state=1)  # Initializes the cross-validator.

        # Prepare to store predictions from different models
        predictions_dict = {}  # Dictionary to store predictions for each model.

        # List of models to train
        models_to_train = [
            # BOW models (commented out as an example)
            # {"name": "Random Forest (BOW)", "type": "BOW", "model": RandomForestClassifier(n_estimators=1000)},
            # Embeddings models
            {"name": "SVC (Embeddings)", "type": "Embeddings", "model": SVC(probability=True)},
            # Support Vector Classifier with probability estimates.
            # LLM models
            {"name": "SciBERT", "type": "LLM", "model_type": "bert", "model_name": "allenai/scibert_scivocab_uncased",
             "model": None},  # SciBERT model for scientific text.
            {"name": "XLNet", "type": "LLM", "model_type": "xlnet", "model_name": "xlnet-base-cased", "model": None},
            # XLNet model.
        ]

        # Cross-validation loop
        for train_idx, test_idx in tqdm(KFoldSplitter.split(Texts, Y), desc="Cross-Validating"):
            # Split data into training and test sets based on current fold
            train_texts, test_texts = Texts[train_idx], Texts[test_idx]  # Training and testing abstracts.
            train_labels, test_labels = Y[train_idx], Y[test_idx]  # Training and testing labels.
            train_IDs, test_IDs = IDs[train_idx], IDs[test_idx]  # Training and testing patent IDs.

            # For BOW models, fit vectorizer within the fold (if BOW models are used)
            vectorizer = TfidfVectorizer(
                max_features=1200,  # Maximum number of features.
                max_df=0.8,  # Maximum document frequency.
                min_df=10,  # Minimum document frequency.
                stop_words=list(STOP_WORDS),  # List of stop words to remove.
                ngram_range=(1, 2),  # Range of n-grams to include.
                tokenizer=word_tokenize,  # Tokenizer function.
                token_pattern=None,  # Ensures compatibility with custom tokenizer.
            )
            train_vectors_bow = vectorizer.fit_transform(
                train_texts)  # Fits the vectorizer on training texts and transforms them.
            test_vectors_bow = vectorizer.transform(test_texts)  # Transforms testing texts using the fitted vectorizer.

            # For Embeddings models
            train_vectors_embeddings = Abstract_Vectors_Embeddings[train_idx]  # Training embeddings.
            test_vectors_embeddings = Abstract_Vectors_Embeddings[test_idx]  # Testing embeddings.

            # Now, train each model
            for model_info in models_to_train:
                name = model_info["name"]  # Model name.
                model_type = model_info["type"]  # Type of model (BOW, Embeddings, LLM).

                if name not in predictions_dict:
                    predictions_dict[name] = {"y_actual": [], "y_predicted": [], "id_s": [],
                                              "y_predicted_p": []}  # Initializes prediction storage for the model.

                if model_type == "BOW":
                    # Handle BOW models
                    model = model_info["model"]  # Retrieves the model instance.

                    # Balance the training data if desired
                    temp_y = list(train_labels)  # Creates a temporary list of training labels.
                    temp_X = train_vectors_bow.todense().tolist()  # Converts training vectors to a dense list.

                    if Reweight:
                        # Repeat balancing to achieve approximately equal class proportions
                        for _ in range(3):  # Repeats the balancing process three times.
                            for i in range(len(train_labels)):  # Iterates over each training example.
                                if (train_labels[i] != 0) and (
                                        np.mean(temp_y) < 0.5):  # Checks if the current label is GenAI and the current proportion is less than 50%.
                                    temp_y.append(train_labels[i])  # Adds a GenAI label.
                                    temp_X.append(temp_X[i])  # Adds the corresponding text vector.

                    # Train the model
                    model.fit(temp_X, temp_y)  # Fits the model to the balanced training data.

                    # Update model_info with the trained model
                    model_info["model"] = model  # Stores the trained model back into the model_info dictionary.

                    # Make predictions
                    y_pred = model.predict(np.asarray(test_vectors_bow.todense()))  # Predicts labels for the test set.
                    y_pred_proba = None
                    if hasattr(model, "predict_proba"):
                        y_pred_proba = model.predict_proba(np.asarray(test_vectors_bow.todense()))[:,
                                       1]  # Predicts probabilities for the positive class (GenAI).

                elif model_type == "Embeddings":
                    # Handle embeddings models
                    model = model_info["model"]  # Retrieves the model instance.

                    # Balance the training data if desired
                    temp_y = list(train_labels)  # Creates a temporary list of training labels.
                    temp_X = list(train_vectors_embeddings)  # Creates a temporary list of training embeddings.

                    if Reweight:
                        # Repeat balancing to achieve approximately equal class proportions
                        for _ in range(3):  # Repeats the balancing process three times.
                            for i in range(len(train_labels)):  # Iterates over each training example.
                                if (train_labels[i] != 0) and (
                                        np.mean(temp_y) < 0.5):  # Checks if the current label is GenAI and the current proportion is less than 50%.
                                    temp_y.append(train_labels[i])  # Adds a GenAI label.
                                    temp_X.append(temp_X[i])  # Adds the corresponding embedding vector.

                    # Convert temp_X to numpy array
                    temp_X = np.array(temp_X)  # Converts the list back to a NumPy array.

                    # Train the model
                    model.fit(temp_X, temp_y)  # Fits the model to the balanced training data.

                    # Update model_info with the trained model
                    model_info["model"] = model  # Stores the trained model back into the model_info dictionary.

                    # Make predictions
                    y_pred = model.predict(test_vectors_embeddings)  # Predicts labels for the test set.
                    y_pred_proba = None
                    if hasattr(model, "predict_proba"):
                        y_pred_proba = model.predict_proba(test_vectors_embeddings)[:,
                                       1]  # Predicts probabilities for the positive class (GenAI).

                elif model_type == "LLM":
                    # Handle LLM models (Large Language Models)
                    model_type_name = model_info["model_type"]  # Type of the LLM (e.g., 'bert', 'xlnet').
                    model_name_or_path = model_info["model_name"]  # The specific pre-trained model to use.

                    # Prepare training DataFrame
                    train_df = pd.DataFrame({"text": train_texts,
                                             "labels": train_labels})  # Creates a DataFrame with training texts and labels.

                    # Initialize the model
                    model = ClassificationModel(
                        model_type_name,  # Type of the transformer model.
                        model_name_or_path,  # Pre-trained model name or path.
                        use_cuda=self.use_cuda,  # Whether to use GPU acceleration.
                        args={
                            "num_train_epochs": 5,  # Number of training epochs.
                            "overwrite_output_dir": True,  # Overwrites the output directory if it exists.
                            "use_early_stopping": False,  # Disables early stopping.
                            "train_batch_size": 50,  # Batch size for training.
                            "do_lower_case": True,  # Converts all characters to lowercase.
                            "silent": False,  # Enables verbose output during training.
                            "no_cache": True,  # Disables caching.
                            "no_save": True,  # Disables saving the model after training.
                        },
                    )

                    # Train the model
                    model.train_model(train_df)  # Trains the model using the training DataFrame.

                    # Update model_info with the trained model
                    model_info["model"] = model  # Stores the trained model back into the model_info dictionary.

                    # Make predictions
                    predictions, raw_outputs = model.predict(list(test_texts))  # Predicts labels for the test set.
                    y_pred = predictions  # Predicted labels.
                    y_pred_proba = None  # Predicted probabilities are not extracted for LLMs.

                    # Clear memory to free up resources
                    gc.collect()  # Collects garbage to free up memory.
                    torch.cuda.empty_cache()  # Frees up unused memory in the GPU.

                else:
                    continue  # Skips if the model type is unknown.

                # Collect predictions
                predictions_dict[name]["y_actual"].extend(test_labels)  # Appends actual labels.
                predictions_dict[name]["y_predicted"].extend(y_pred)  # Appends predicted labels.
                predictions_dict[name]["id_s"].extend(test_IDs)  # Appends patent IDs.
                if y_pred_proba is not None:
                    predictions_dict[name]["y_predicted_p"].extend(
                        y_pred_proba)  # Appends predicted probabilities if available.
                else:
                    predictions_dict[name]["y_predicted_p"].extend(
                        [np.nan] * len(y_pred))  # Appends NaN if probabilities are not available.

        # Now, after all folds are done, evaluate each model
        for model_info in models_to_train:
            name = model_info["name"]  # Model name.
            y_actual = predictions_dict[name]["y_actual"]  # Actual labels.
            y_predicted = predictions_dict[name]["y_predicted"]  # Predicted labels.
            id_s = predictions_dict[name]["id_s"]  # Patent IDs.
            y_predicted_p = predictions_dict[name]["y_predicted_p"]  # Predicted probabilities.

            # Evaluate metrics
            Share = np.round(np.mean(y_predicted), 3)  # Calculates the average share of patents classified as GenAI.
            Accuracy = accuracy_score(y_actual, y_predicted)  # Overall accuracy of the model.
            if len(set(y_actual)) > 1 and len(set(y_predicted)) > 1:
                ROC = roc_auc_score(y_actual,
                                    y_predicted)  # Measures the model's ability to distinguish between classes.
            else:
                ROC = None  # Sets ROC to None if it's not applicable.
            Precision = precision_score(y_actual, y_predicted, zero_division=0)  # Accuracy of positive predictions.
            Recall = recall_score(y_actual, y_predicted, zero_division=0)  # Ability to find all positive instances.
            F1 = f1_score(y_actual, y_predicted, zero_division=0)  # Harmonic mean of precision and recall.
            CM = confusion_matrix(y_actual, y_predicted)  # Confusion matrix to understand the types of errors.

            # Handle confusion matrix
            try:
                FN = CM[1][0]  # False Negatives count.
                FP = CM[0][1]  # False Positives count.
                TN = CM[0][0]  # True Negatives count.
                TP = CM[1][1]  # True Positives count.
            except IndexError:
                FN = FP = TN = TP = None  # Sets counts to None if there's an error.

            # Add metrics to results
            self.results.append(
                [
                    name,  # Model name.
                    Share,  # Share of GenAI classifications.
                    TP,  # True Positives.
                    FN,  # False Negatives.
                    FP,  # False Positives.
                    TN,  # True Negatives.
                    np.round(Accuracy, 3),  # Rounded Accuracy.
                    np.round(ROC, 3) if ROC is not None else None,  # Rounded ROC or None.
                    np.round(Precision, 3),  # Rounded Precision.
                    np.round(Recall, 3),  # Rounded Recall.
                    np.round(F1, 3),  # Rounded F1 Score.
                ]
            )

            # Save classification results
            self.classified_values.append(
                list(zip(len(id_s) * [name], id_s, y_actual, y_predicted))
            )  # Stores the results for each patent.

            # Save predicted probabilities
            self.classified_values_p.append(
                list(zip(len(id_s) * [name], id_s, y_actual, y_predicted_p))
            )  # Stores the predicted probabilities.

        # After all folds are completed, save the trained models
        for model_info in models_to_train:
            name = model_info["name"]  # Model name.
            model_type = model_info["type"]  # Type of model (BOW, Embeddings, LLM).
            model = model_info["model"]  # Trained model instance.

            if model_type == "BOW":
                # Save the model and vectorizer
                model_filename = f'Models/{name.replace(" ", "_")}_model_final.joblib'  # Defines the filename for saving the model.
                vectorizer_filename = 'Models/bow_vectorizer_final.joblib'  # Filename for the vectorizer.
                joblib.dump(model, model_filename)  # Saves the BOW model to a file.
                joblib.dump(self.vectorizer, vectorizer_filename)  # Saves the BOW vectorizer to a file.
                print(f"{name} model and vectorizer saved after completion of all training folds.")  # Confirms saving.

            elif model_type == "Embeddings":
                # Save the model
                model_filename = f'Models/{name.replace(" ", "_")}_model_final.joblib'  # Defines the filename for saving the model.
                joblib.dump(model, model_filename)  # Saves the embeddings model to a file.
                print(f"{name} model saved after completion of all training folds.")  # Confirms saving.

            elif model_type == "LLM":
                # Save the model
                model_save_path = f"Models/{name.replace(' ', '_')}_model_final"  # Defines the path for saving the LLM model.
                model.save_model(model_save_path)  # Saves the LLM model to the specified path.
                print(f"{name} model saved after completion of all training folds.")  # Confirms saving.

    def output_results(self):
        """
        Output the classification results and save them.

        This function converts the collected results into a structured format, saves them as CSV files,
        and displays them for review. It also creates ensemble predictions using majority voting.
        """
        # Convert the results list to a DataFrame
        self.results_table = pd.DataFrame(
            self.results,
            columns=[
                "Name",
                "Share",
                "True-Positives",
                "False-Negatives",
                "False-Positives",
                "True-Negatives",
                "Accuracy",
                "AUC",
                "Precision",
                "Recall",
                "F1",
            ],
        )  # Creates a table with all the collected performance metrics.

        # Add a new column 'Type' with the value 'Individual' for all entries
        self.results_table["Type"] = "Individual"  # Specifies that the metrics are for individual models.

        # Rearrange columns for better readability
        self.results_table = self.results_table[
            [
                "Name",
                "Type",
                "Share",
                "True-Positives",
                "False-Negatives",
                "False-Positives",
                "True-Negatives",
                "Accuracy",
                "AUC",
                "Precision",
                "Recall",
                "F1",
            ]
        ]  # Orders the columns in a logical sequence.

        # Save the results to a CSV file, sorted by descending accuracy
        output_path = f"Output/Classification_Model_GenAI_Performance_{self.total_entries}_{self.total_ratio}.csv"  # Defines the filename for saving the results.
        self.results_table.sort_values("Accuracy", ascending=False).to_csv(
            output_path, index=False
        )  # Saves the performance metrics to a CSV file for further analysis.
        print(f"Results saved to {output_path}")  # Confirms that the results have been saved.

        # Display the results in the console
        print(self.results_table.sort_values("Accuracy",
                                             ascending=False))  # Prints the sorted results table to the console.

        # Output the classification results for the training dataset
        Final = None  # Initializes the Final DataFrame.

        # Loop through the classification results for each model
        for i in range(len(self.classified_values)):
            Temp = pd.DataFrame(
                self.classified_values[i], columns=["Model", "id", "Actual", "Predicted"]
            )  # Creates a temporary DataFrame for the current model's predictions.

            name = Temp.iloc[0]["Model"]  # Retrieves the model name from the first row.

            if i == 0:
                Temp = Temp[["id", "Actual", "Predicted"]]  # Selects relevant columns.
                Temp.columns = ["id", "Actual", name]  # Renames columns to include the model name.
                Final = Temp  # Initializes the Final DataFrame with the first model's results.
            else:
                Temp = Temp[["id", "Predicted"]]  # Selects relevant columns.
                Temp.columns = ["id", name]  # Renames columns to include the model name.
                Final = Final.merge(Temp, on="id")  # Merges with the Final DataFrame based on 'id'.

        # Save the final DataFrame to a CSV file
        final_output_path = (
            f"Output/Classification_GenAI_Results_{self.total_entries}_{self.total_ratio}.csv"
        )  # Defines the filename for saving the detailed classification results.
        Final.to_csv(final_output_path, index=False)  # Saves the detailed classification results.
        print(f"Classification results saved to {final_output_path}")  # Confirms saving.

        # Now, create ensemble predictions using majority voting
        prediction_cols = [col for col in Final.columns if
                           col not in ["id", "Actual"]]  # Identifies prediction columns.
        Final["Ensemble_Predicted"] = Final[prediction_cols].mode(axis=1)[
            0]  # Creates ensemble predictions by taking the mode of individual predictions.

        # Evaluate ensemble predictions
        y_actual = Final["Actual"]  # Actual labels.
        y_predicted = Final["Ensemble_Predicted"]  # Ensemble predicted labels.

        # Evaluate metrics for the ensemble
        Share = np.round(np.mean(y_predicted), 3)  # Calculates the average share of patents classified as GenAI.
        Accuracy = accuracy_score(y_actual, y_predicted)  # Overall accuracy of the ensemble model.
        if len(set(y_actual)) > 1 and len(set(y_predicted)) > 1:
            ROC = roc_auc_score(y_actual,
                                y_predicted)  # Measures the ensemble model's ability to distinguish between classes.
        else:
            ROC = None  # Sets ROC to None if it's not applicable.
        Precision = precision_score(y_actual, y_predicted, zero_division=0)  # Accuracy of positive predictions.
        Recall = recall_score(y_actual, y_predicted, zero_division=0)  # Ability to find all positive instances.
        F1 = f1_score(y_actual, y_predicted, zero_division=0)  # Harmonic mean of precision and recall.
        CM = confusion_matrix(y_actual, y_predicted)  # Confusion matrix for the ensemble model.

        # Handle confusion matrix
        try:
            FN = np.round(CM[0][0] / (CM[0][0] + CM[1][0]), 3)  # False Negatives proportion.
            FP = np.round(CM[0][1] / (CM[0][1] + CM[1][1]), 3)  # False Positives proportion.
            TN = np.round(CM[1][0] / (CM[0][0] + CM[1][0]), 3)  # True Negatives proportion.
            TP = np.round(CM[1][1] / (CM[0][1] + CM[1][1]), 3)  # True Positives proportion.
        except ZeroDivisionError:
            FN = FP = TN = TP = None  # Sets counts to None if there's an error.

        # Add ensemble metrics to results
        self.results.append(
            [
                "Ensemble",  # Name of the ensemble model.
                Share,  # Share of GenAI classifications.
                TP,  # True Positives.
                FN,  # False Negatives.
                FP,  # False Positives.
                TN,  # True Negatives.
                np.round(Accuracy, 3),  # Rounded Accuracy.
                np.round(ROC, 3) if ROC is not None else None,  # Rounded ROC or None.
                np.round(Precision, 3),  # Rounded Precision.
                np.round(Recall, 3),  # Rounded Recall.
                np.round(F1, 3),  # Rounded F1 Score.
            ]
        )

        # Update results_table
        self.results_table = pd.DataFrame(
            self.results,
            columns=[
                "Name",
                "Share",
                "True-Positives",
                "False-Negatives",
                "False-Positives",
                "True-Negatives",
                "Accuracy",
                "AUC",
                "Precision",
                "Recall",
                "F1",
            ],
        )  # Creates an updated table with all results, including the ensemble.

        self.results_table["Type"] = "Individual"  # Specifies that the metrics are for individual models.
        self.results_table.loc[self.results_table[
                                   "Name"] == "Ensemble", "Type"] = "Ensemble"  # Changes the type to 'Ensemble' for the ensemble model.

        # Rearrange columns for better readability
        self.results_table = self.results_table[
            [
                "Name",
                "Type",
                "Share",
                "True-Positives",
                "False-Negatives",
                "False-Positives",
                "True-Negatives",
                "Accuracy",
                "AUC",
                "Precision",
                "Recall",
                "F1",
            ]
        ]  # Orders the columns in a logical sequence.

        # Save updated results table
        output_path = f"Output/Classification_Model_GenAI_Performance_{self.total_entries}_{self.total_ratio}.csv"  # Defines the filename for saving the updated results.
        self.results_table.sort_values("Accuracy", ascending=False).to_csv(
            output_path, index=False
        )  # Saves the updated performance metrics to a CSV file.
        print(f"Updated Results saved to {output_path}")  # Confirms that the updated results have been saved.

        # Display the updated results in the console
        print(self.results_table.sort_values("Accuracy",
                                             ascending=False))  # Prints the sorted results table to the console.

        # Save the final DataFrame with ensemble predictions
        final_output_path = f"Output/Classification_GenAI_Results_with_Ensemble_{self.total_entries}_{self.total_ratio}.csv"  # Defines the filename for saving the final classification results with ensemble.
        Final.to_csv(final_output_path,
                     index=False)  # Saves the final classification results with ensemble predictions.
        print(f"Classification results with ensemble saved to {final_output_path}")  # Confirms saving.

    def plot_all_metrics(self):
        """
        Creates and saves a grouped bar chart for all metrics,
        displaying individual metric values on the bars.

        This visualization helps in comparing the performance metrics of different models side by side.
        """
        df_plot = self.results_table[["Name"] + self.metrics]  # Selects the 'Name' and metric columns for plotting.

        num_models = len(df_plot["Name"])  # Counts the number of models.
        num_metrics = len(self.metrics)  # Counts the number of metrics.

        ind = np.arange(num_models)  # The x locations for the groups.
        total_width = 0.8  # Total width for all bars in a group.
        width = total_width / num_metrics  # Width of each individual bar.

        fig, ax = plt.subplots(figsize=(12, 6))  # Creates a figure and a set of subplots with a specified size.

        for i, metric in enumerate(self.metrics):
            # Positioning of bars within each group.
            offset = (i - num_metrics / 2) * width + width / 2  # Calculates the offset for each metric.
            positions = ind + offset  # Calculates the positions for the bars.
            bars = ax.bar(positions, df_plot[metric], width, label=metric)  # Creates a bar for each metric.

            # Adding metric values on the bars for clarity.
            for bar in bars:
                height = bar.get_height()  # Gets the height of the bar.
                ax.annotate(
                    f"{height:.2f}",  # Formats the height to two decimal places.
                    xy=(bar.get_x() + bar.get_width() / 2, height),  # Position for the annotation.
                    xytext=(0, 3),  # Vertical offset in points.
                    textcoords="offset points",  # Specifies that the text position is offset by points.
                    ha="center",  # Horizontally centers the text.
                    va="bottom",  # Vertically aligns the text to the bottom of the annotation point.
                    fontsize=8,  # Sets the font size of the annotation.
                )  # Places the annotation above the bar.

        ax.set_xlabel("Model Name")  # Labels the x-axis.
        ax.set_ylabel("Scores")  # Labels the y-axis.
        ax.set_title(
            f"Comparison of Model Performance ({self.total_entries} patents, ratio: {self.total_ratio})"
        )  # Sets a descriptive title that includes the number of patents and the ratio.
        ax.set_xticks(ind)  # Sets the positions of the x-axis ticks.
        ax.set_xticklabels(df_plot["Name"], rotation=45,
                           ha="right")  # Labels the x-axis ticks with model names, rotated for better readability.
        ax.legend()  # Adds a legend to differentiate the metrics.

        plt.tight_layout()  # Adjusts the padding between and around subplots to prevent overlapping elements.
        plt.savefig(
            f"Figures/model_performance_grouped_bar_{self.total_entries}_{self.total_ratio}.png",
            dpi=300,
        )  # Saves the figure as a high-resolution PNG file.
        plt.show()  # Displays the plot to the user.


# -------------------------------------------------------------
# Main Execution
# -------------------------------------------------------------
# The following code runs when the script is executed directly.
# To run the code, execute the following command in the terminal:
# python class_ensembling_majority.py

if __name__ == "__main__":
    # Ensure necessary directories exist
    if not os.path.exists("Figures"):
        os.makedirs("Figures")  # Creates the 'Figures' directory to store plots.
    if not os.path.exists("Output"):
        os.makedirs("Output")  # Creates the 'Output' directory to store result CSV files.

    # Paths to data files
    data_path = os.path.join(
        "Training Data", "20240819_WIPO Patents GenAI US matched_1-1000.csv"
    )  # Defines the path to the main training data CSV file.
    delimiter = ";"  # Specifies that the CSV file uses a semicolon to separate values.

    anti_seed_path = os.path.join("Training Data",
                                  "4K Patents - AI 20p.csv")  # Defines the path to the anti-seed data CSV file.

    # Initialize the classifier
    classifier = PatentEnsembleClassifier(data_path, anti_seed_path,
                                          delimiter)  # Creates an instance of the PatentEnsembleClassifier.

    # Load and prepare data
    classifier.load_data()  # Reads and processes the main training data.
    classifier.load_anti_seed(n=3146)  # Loads and integrates the anti-seed data with a specified number of entries.
    classifier.prepare_data()  # Prepares the data by extracting features and calculating label distributions.

    # Preprocess data for different models
    classifier.preprocess_bow()  # Prepares data for the Bag-of-Words model.
    classifier.preprocess_embeddings()  # Prepares data for the embeddings model.

    # Train and evaluate models
    classifier.train_and_evaluate_models()  # Trains each classifier using cross-validation and evaluates their performance.

    # Output results and plots
    classifier.output_results()  # Outputs and saves the classification results.
    classifier.plot_all_metrics()  # Generates a bar chart comparing the performance of all classifiers.