###############################################
# Import necessary libraries #
###############################################
# These lines import various tools and libraries that the script will use.
import pandas as pd  # A powerful library for data manipulation and analysis, especially for working with tables of data.
import numpy as np  # A library that supports large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays.
import os  # Provides functions for interacting with the operating system, such as reading or writing files and creating directories.
import matplotlib.pyplot as plt  # A plotting library used for creating static, animated, and interactive visualizations.
import seaborn as sns  # A library built on top of matplotlib that provides a higher-level interface for drawing attractive statistical graphics.
from sklearn.model_selection import StratifiedKFold  # A tool for splitting data into training and testing sets while maintaining the percentage of samples for each class.
from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix  # Functions to evaluate the performance of machine learning models.
from sklearn.svm import SVC  # Support Vector Classifier, a type of machine learning model used for classification tasks.
from sklearn.naive_bayes import MultinomialNB  # A Naive Bayes classifier for multinomially distributed data, often used for text classification.
from sklearn.linear_model import LogisticRegression  # A linear model for classification tasks.
from sklearn.ensemble import RandomForestClassifier  # An ensemble model that builds multiple decision trees and merges their results for better accuracy.
from sklearn.feature_extraction.text import TfidfVectorizer  # Converts a collection of raw documents to a matrix of TF-IDF features.
from tqdm import tqdm  # Provides a progress bar for loops, making it easier to track the progress of long-running operations.
from nltk.tokenize import word_tokenize  # Splits sentences into words (tokens) using Natural Language Toolkit (NLTK).
from spacy.lang.en import STOP_WORDS  # A list of common English stop words (e.g., 'the', 'and') provided by spaCy.
import warnings  # Used to control warning messages generated by the code.

# Warnungen deaktivieren
warnings.filterwarnings("ignore")  # This line tells Python to ignore all warning messages, keeping the output clean.

# Define the PatentClassifier class
class PatentClassifier:
    def __init__(self, data_path, delimiter):
        """
        Initialize the PatentClassifier with data path and delimiter.

        Parameters:
        - data_path: Path to the training data CSV file.
        - delimiter: Character used to separate values in the CSV file (e.g., ',', ';').
        """
        self.data_path = data_path  # Stores the path to the main training data.
        self.delimiter = delimiter  # Stores the delimiter used in the CSV file.
        self.data = None  # Placeholder for the combined dataset.
        self.IDs = None  # Placeholder for patent IDs.
        self.texts = None  # Placeholder for patent abstracts.
        self.labels = None  # Placeholder for labels indicating GenAI patents (1) or not (0).
        self.total_entries = None  # Placeholder for the total number of patents.
        self.total_ratio = None  # Placeholder for the ratio of GenAI to non-GenAI patents.
        self.results = []  # List to store performance results of each model.
        self.classified_values = []  # List to store individual classification results (actual vs. predicted).
        self.classified_values_p = []  # List to store predicted probabilities, if available.
        self.feature_names = None  # Placeholder for the names of the features extracted from the text.
        self.vectorizer = None  # Placeholder for the TF-IDF vectorizer.
        self.text_vectors = None  # Placeholder for the numerical representation of the patent abstracts.
        self.results_table = None  # Placeholder for the table of results.
        self.metrics = ['Accuracy', 'AUC', 'Precision', 'Recall', 'F1']  # List of performance metrics to evaluate.

    def load_data(self):
        """
        Load and preprocess the training data from a CSV file.

        This function reads the CSV file containing patent data, processes it by creating a new label column
        indicating whether each patent is related to Generative AI (GenAI), and stores the processed data.
        """
        # Load CSV file with patent data
        self.data = pd.read_csv(self.data_path, delimiter=self.delimiter)  # Reads the CSV file into a pandas DataFrame.

        # Categorize: if 'Finales Resultat' >= 1, set 'label_genai' to 1, else 0
        self.data['label_genai'] = (self.data['Finales Resultat'] >= 1).astype(int)  # Creates a new column 'label_genai' based on the 'Finales Resultat' column.

    def load_anti_seed(self, n):
        """
        Load and integrate anti-seed data to balance the dataset.

        Parameters:
        - n: Number of anti-seed entries to include in the dataset.

        This function reads additional data containing non-GenAI patents to balance the dataset, ensuring
        that there are enough non-GenAI examples for the model to learn effectively.
        """
        # Load AI patents to create an anti-seed set, use path.join to function for mac and windows
        anti_seed_path = os.path.join(".", "Training Data", "4K Patents - AI 20p.csv")  # Defines the path to the anti-seed data CSV.
        anti_seed = pd.read_csv(anti_seed_path, delimiter=',')  # Reads the anti-seed CSV file into a pandas DataFrame.

        # Filter patents without AI content (actual == 0)
        anti_seed = anti_seed[anti_seed['actual'] == 0]  # Filters the DataFrame to include only non-GenAI patents.

        # Limit anti-seed dataset to n patents
        anti_seed = anti_seed[:n]  # Selects the first 'n' entries from the anti-seed DataFrame.

        # Adjust columns in the anti-seed set to combine with training data
        anti_seed['label_genai'] = 0  # Sets the 'label_genai' column to 0 for all anti-seed patents (non-GenAI).

        # Unify column names (adjust if columns are different)
        anti_seed = anti_seed.rename(columns={
            'app number': 'patent_id',  # Renames 'app number' to 'patent_id'.
            'abstract': 'patent_abstract'  # Renames 'abstract' to 'patent_abstract'.
        })  # Ensures consistency with the main training data.

        # Select relevant columns for merging
        anti_seed = anti_seed[['patent_id', 'patent_abstract', 'label_genai']]  # Keeps only the necessary columns.

        # Combine training data with anti-seed data
        self.data = pd.concat([self.data[['patent_id', 'patent_abstract', 'label_genai']], anti_seed], ignore_index=True)  # Merges the main data with the anti-seed data to create a balanced dataset.

    def preprocess_data(self):
        """
        Prepare data for text classification and vectorization.

        This function extracts the necessary information from the combined dataset, calculates the distribution
        of labels, and transforms the text data into numerical vectors using TF-IDF vectorization.
        """
        # Save data into lists for text classification
        self.IDs = self.data['patent_id'].values  # Extracts patent IDs as a NumPy array.
        self.texts = self.data['patent_abstract'].tolist()  # Extracts patent abstracts as a list.
        self.labels = self.data['label_genai'].tolist()  # Extracts labels (1 or 0) as a list.

        # Calculate the distribution of 'label_genai'
        label_counts = self.data['label_genai'].value_counts(normalize=True) * 100  # Calculates the percentage of each label.
        self.total_entries = len(self.data)  # Counts the total number of patents.
        self.total_ratio = f"{label_counts.get(1, 0):.0f}-{label_counts.get(0, 0):.0f}"  # Formats the ratio as "GenAI%-Non-GenAI%".

        # Output the distribution and total count
        print(f"Share of entries with '1': {label_counts.get(1, 0):.2f}%")  # Prints the percentage of GenAI patents.
        print(f"Share of entries with '0': {label_counts.get(0, 0):.2f}%")  # Prints the percentage of non-GenAI patents.
        print(f"1/0 Ratio: {self.total_ratio}")  # Prints the ratio of GenAI to non-GenAI patents.
        print(f"Total number of entries: {self.total_entries}")  # Prints the total number of patents.

        # Define model parameters for TF-IDF vectorization
        MINDF = 10  # Minimum number of documents a word must appear in to be included.
        MAXDF = 0.8  # Maximum proportion of documents a word can appear in to be included.
        MAX_FEATURES = 1200  # Maximum number of features (words) to consider.
        NGRAM_RANGE = (1, 2)  # Range of n-grams to include (e.g., single words and pairs of words).

        # Load stop words to ignore during vectorization
        stop_words = list(STOP_WORDS)  # Retrieves a list of common English stop words from spaCy.

        # Define tokenizer function to split text into words and remove non-alphanumeric tokens
        def simple_tokenizer(text):
            tokens = word_tokenize(text.lower())  # Converts text to lowercase and splits into words.
            return [token for token in tokens if token.isalnum()]  # Keeps only alphanumeric tokens.

        # Define TF-IDF vectorizer to convert text data into numerical vectors
        self.vectorizer = TfidfVectorizer(
            max_features=MAX_FEATURES,  # Limits the number of features to the top 'MAX_FEATURES'.
            max_df=MAXDF,  # Ignores words that appear in more than 'MAXDF' proportion of documents.
            min_df=MINDF,  # Ignores words that appear in fewer than 'MINDF' documents.
            stop_words=stop_words,  # Removes common stop words.
            ngram_range=NGRAM_RANGE,  # Considers both single words and pairs of words.
            tokenizer=simple_tokenizer  # Uses the custom tokenizer defined above.
        )

        # Transform text data into TF-IDF matrix and extract feature names
        self.text_vectors = self.vectorizer.fit_transform(self.texts)  # Converts the list of abstracts into a numerical matrix.
        self.feature_names = self.vectorizer.get_feature_names_out()  # Retrieves the names of the features (words) used in the vectorization.

        # Output the first few feature names for verification
        print(f"First features: {self.feature_names[:10]}")  # Prints the first 10 feature names.
        print(f"Number of extracted features: {len(self.feature_names)}")  # Prints the total number of features extracted.

    def train_and_evaluate(self):
        """
        Define classifiers, perform cross-validation, and evaluate models.

        This function sets up different machine learning models, trains them using cross-validation,
        evaluates their performance using various metrics, and stores the results for comparison.
        """
        # Define classifiers to test
        CLASSIFIERS = [
            ["Support Vector Classifier (RBF)", SVC()],  # SVC with default RBF kernel.
            ["Naive Bayes", MultinomialNB()],  # Multinomial Naive Bayes classifier.
            ["Logistic Regression", LogisticRegression()],  # Logistic Regression classifier.
            ["Random Forest", RandomForestClassifier(n_estimators=1000)]  # Random Forest classifier with 1000 trees.
        ]

        NUM_OF_SPLITS = 5  # Number of folds for cross-validation.
        Reweight = True  # Option to manually adjust class distribution during training.

        # Convert labels to numpy array for efficient processing
        Y = np.array(self.labels)  # Array of labels (1 or 0).
        IDs = np.array(self.IDs)  # Array of patent IDs.
        Abstract_Vectors = self.text_vectors  # Numerical representation of patent abstracts.

        # Iterate over each classifier to train and evaluate
        for CL in tqdm(CLASSIFIERS, desc="Evaluating Classifiers"):
            name, Model = CL  # Unpack the classifier name and the model instance.

            y_actual, y_predicted, y_predicted_p = [], [], []  # Lists to store actual labels, predicted labels, and predicted probabilities.
            id_s = []  # List to store patent IDs for the current fold.

            # Stratified K-Fold ensures class distribution is preserved across folds
            KFoldSplitter = StratifiedKFold(n_splits=NUM_OF_SPLITS, shuffle=True, random_state=1)  # Initializes the cross-validator.

            # Perform cross-validation
            for train_i, test_i in tqdm(KFoldSplitter.split(Abstract_Vectors, Y),
                                        desc='Cross-Validating', leave=True, total=NUM_OF_SPLITS):
                # Split data into training and test sets based on current fold
                train_X, test_X = Abstract_Vectors[train_i], Abstract_Vectors[test_i]  # Training and testing features.
                train_y, test_y = Y[train_i], Y[test_i]  # Training and testing labels.
                Train_IDs, Test_IDs = IDs[train_i], IDs[test_i]  # Training and testing patent IDs.

                # Balance the training data if desired
                temp_y = list(train_y)  # Create a temporary list of training labels.
                temp_X = train_X.todense().tolist()  # Convert the sparse matrix to a dense list of lists for compatibility.

                if Reweight:
                    # Repeat balancing up to three times to achieve approximately equal class proportions
                    for _ in range(3):
                        for i in range(len(train_y)):
                            if (train_y[i] != 0) and (np.mean(temp_y) < 0.5):  # Check if the current label is GenAI and the current proportion is less than 50%.
                                temp_y.append(train_y[i])  # Add a GenAI label.
                                temp_X.append(temp_X[i])  # Add the corresponding text vector.

                # Train the model with the training data
                Model.fit(temp_X, temp_y)  # Fits the model to the training data.

                # Make predictions on the test data
                y_pred = Model.predict(np.asarray(test_X.todense()))  # Predicts labels for the test set.

                # Convert predictions to binary values (0/1)
                y_pred = [1 if y > 0.5 else 0 for y in y_pred]  # Ensures predictions are binary.

                # Save actual and predicted values and IDs
                y_actual += list(test_y)  # Append actual labels.
                y_predicted += y_pred  # Append predicted labels.
                id_s += list(Test_IDs)  # Append patent IDs.

                # Save predicted probabilities for Random Forest
                if name == "Random Forest":
                    y_pred_p = Model.predict_proba(np.asarray(test_X.todense()))  # Predicts probabilities for each class.
                    y_pred_p = [y[1] for y in y_pred_p]  # Extracts the probability of the positive class (GenAI).
                    y_predicted_p += y_pred_p  # Appends predicted probabilities.

            # After all folds are processed, evaluate the overall performance
            Share = np.round(np.mean(y_predicted), 3)  # Calculates the average share of patents classified as GenAI.

            # Calculate key performance metrics
            Accuracy = accuracy_score(y_actual, y_predicted)  # Overall accuracy of the model.
            ROC = roc_auc_score(y_actual, y_predicted)  # Ability of the model to distinguish between classes.
            Precision = precision_score(y_actual, y_predicted)  # Accuracy of positive predictions.
            Recall = recall_score(y_actual, y_predicted)  # Ability to find all positive instances.
            F1 = f1_score(y_actual, y_predicted)  # Harmonic mean of precision and recall.

            # Create confusion matrix to analyze types of errors
            CM = confusion_matrix(y_actual, y_predicted)  # Matrix showing true vs. predicted classifications.

            # Calculate proportions of error types (rounded to 3 decimal places)
            try:
                FN = np.round(CM[0][0] / (CM[0][0] + CM[1][0]), 3)  # False Negatives proportion.
                FP = np.round(CM[0][1] / (CM[0][1] + CM[1][1]), 3)  # False Positives proportion.
                TN = np.round(CM[1][0] / (CM[0][0] + CM[1][0]), 3)  # True Negatives proportion.
                TP = np.round(CM[1][1] / (CM[0][1] + CM[1][1]), 3)  # True Positives proportion.
            except ZeroDivisionError:
                FN = FP = TN = TP = None  # If division by zero occurs, set all to None.

            # Add metrics to the results list
            self.results.append([
                name, Share, TP, FN, FP, TN,
                np.round(Accuracy, 3),
                np.round(ROC, 3),
                np.round(Precision, 3),
                np.round(Recall, 3),
                np.round(F1, 3)
            ])  # Appends the performance metrics for the current model.

            # Save classification results (actual vs. predicted)
            self.classified_values.append(list(zip(len(id_s) * [name], id_s, y_actual, y_predicted)))  # Stores the results for each patent.

            # Save predicted probabilities for Random Forest
            if name == "Random Forest":
                self.classified_values_p.append(list(zip(len(id_s) * [name], id_s, y_actual, y_predicted_p)))  # Stores the predicted probabilities.

        # Convert the list of model performance metrics into a DataFrame
        self.results_table = pd.DataFrame(self.results, columns=[
            "Name", "Share", "True-Positives", "False-Negatives",
            "False-Positives", "True-Negatives", "Accuracy", "AUC",
            "Precision", "Recall", "F1"
        ])  # Creates a table with all the collected performance metrics.

        # Add a column indicating the type of analysis
        self.results_table["Type"] = "Bag of Words"  # Specifies that the Bag of Words technique was used for feature extraction.

        # Rearrange columns for better readability
        self.results_table = self.results_table[[
            "Name", "Type", "Share", "True-Positives", "False-Negatives",
            "False-Positives", "True-Negatives", "Accuracy", "AUC",
            "Precision", "Recall", "F1"
        ]]  # Orders the columns in a logical sequence.

        # Sort the table by accuracy in descending order and save the results as a CSV file
        self.results_table.sort_values("Accuracy", ascending=False).to_csv(
            f"./Output/GenAI_BOW_Model_Classification_Performance_{self.total_entries}_{self.total_ratio}.csv",
            index=False  # Does not include the row index in the saved CSV.
        )  # Saves the performance metrics to a CSV file for further analysis.
        print(self.results_table.sort_values("Accuracy", ascending=False))  # Prints the sorted results table to the console.

        # Output the prediction results for the training dataset

        # Create a DataFrame for each classification result and merge them
        for i, classified_values in enumerate(self.classified_values):
            Temp = pd.DataFrame(classified_values, columns=['Model', 'id', 'Actual', 'Predicted'])  # Creates a temporary DataFrame.

            # Rename columns based on the model name
            if i == 0:
                name = Temp['Model'].iloc[0]  # Retrieves the model name from the first row.
                Temp = Temp[['id', 'Actual', 'Predicted']]  # Selects relevant columns.
                Temp.columns = ['id', 'Actual', name]  # Renames columns to include the model name.
                Final = Temp  # Initializes the Final DataFrame with the first model's results.
            else:
                name = Temp['Model'].iloc[0]  # Retrieves the model name from the first row.
                Temp = Temp[['id', 'Predicted']]  # Selects relevant columns.
                Temp.columns = ['id', name]  # Renames columns to include the model name.
                Final = Final.merge(Temp, on='id')  # Merges with the Final DataFrame based on 'id'.

        # Save the merged classification results as a CSV file
        Final.to_csv(f"./Output/GenAI_BOW_Classification_Results_{self.total_entries}_{self.total_ratio}.csv", index=False)  # Saves the detailed classification results.

        # Output the predicted probabilities only for the Random Forest model

        # Create a DataFrame for the probabilities and merge them
        for i, classified_values_p in enumerate(self.classified_values_p):
            Temp = pd.DataFrame(classified_values_p, columns=['Model', 'id', 'Actual', 'Predicted'])  # Creates a temporary DataFrame for probabilities.

            if i == 0:
                name = Temp['Model'].iloc[0]  # Retrieves the model name from the first row.
                Temp = Temp[['id', 'Actual', 'Predicted']]  # Selects relevant columns.
                Temp.columns = ['id', 'Actual', name]  # Renames columns to include the model name.
                Final = Temp  # Initializes the Final DataFrame with the first model's probability results.
            else:
                name = Temp['Model'].iloc[0]  # Retrieves the model name from the first row.
                Temp = Temp[['id', 'Predicted']]  # Selects relevant columns.
                Temp.columns = ['id', name]  # Renames columns to include the model name.
                Final = Final.merge(Temp, on='id')  # Merges with the Final DataFrame based on 'id'.

        # Save the probabilities as a CSV file
        Final.to_csv(f"./Output/GenAI_RandomForest_BOW_[Predicted Probabilities]_{self.total_entries}_{self.total_ratio}.csv", index=False)  # Saves the predicted probabilities for the Random Forest model.

    def plot_all_metrics(self):
        """
        Creates and saves a grouped bar chart for all metrics,
        displaying individual metric values on the bars.

        Visualizes the performance metrics of the model.
        """
        df_plot = self.results_table[['Name'] + self.metrics]  # Selects the 'Name' and metric columns for plotting.

        num_models = len(df_plot['Name'])  # Counts the number of models.
        num_metrics = len(self.metrics)  # Counts the number of metrics.

        ind = np.arange(num_models)  # The x locations for the groups.
        total_width = 0.8  # Total width for all bars in a group.
        width = total_width / num_metrics  # Width of each individual bar.

        fig, ax = plt.subplots(figsize=(12, 6))  # Creates a figure and a set of subplots with a specified size.

        for i, metric in enumerate(self.metrics):
            # Positioning of bars within each group.
            offset = (i - num_metrics / 2) * width + width / 2
            positions = ind + offset
            bars = ax.bar(positions, df_plot[metric], width, label=metric)  # Creates a bar for each metric.

            # Adding metric values on the bars for clarity.
            for bar in bars:
                height = bar.get_height()
                ax.annotate(f'{height:.2f}',
                            xy=(bar.get_x() + bar.get_width() / 2, height),
                            xytext=(0, 3),  # Vertikaler Offset in Punkten
                            textcoords="offset points",
                            ha='center', va='bottom', fontsize=8)  # Aligns the text above the bar.

        ax.set_xlabel('Modellname')  # Labels the x-axis.
        ax.set_ylabel('Scores')  # Labels the y-axis.
        ax.set_title(f'Comparison Bag of Words Model Performance ({self.total_entries} patents, ratio: {self.total_ratio})')  # Sets the title of the chart.
        ax.set_xticks(ind)  # Sets the positions of the x-axis ticks.
        ax.set_xticklabels(df_plot['Name'], rotation=45, ha='right')  # Labels the x-axis ticks with model names, rotated for better readability.
        ax.legend()  # Adds a legend to differentiate the metrics.

        plt.tight_layout()  # Adjusts the padding between and around subplots to prevent overlapping elements.
        plt.savefig(f"Figures/bow_model_performance_grouped_bar_{self.total_entries}_{self.total_ratio}.png", dpi=300)  # Saves the figure as a high-resolution PNG file.
        plt.show()  # Displays the plot to the user.

# -------------------------------------------------------------
# Main Execution
# -------------------------------------------------------------

# The following code runs when the script is executed directly.
# It sets up the environment, initializes the classifier, loads and preprocesses data,
# trains and evaluates the models, and creates plots of the results.
# To run the code, execute the following command in the terminal:
# python class_bow_genai.py

if __name__ == '__main__':

    # Ensure that the 'Figures' directory exists; create it if it doesn't.
    if not os.path.exists("Figures"):
        os.makedirs("Figures")  # Creates the 'Figures' directory to store plots.

    # Ensure that the 'Output' directory exists; create it if it doesn't.
    if not os.path.exists("Output"):
        os.makedirs("Output")  # Creates the 'Output' directory to store result CSV files.

    # Dataset parameters, usage of path.join to function for mac and windows
    data_path = os.path.join(".", "Training Data", "20240819_WIPO Patents GenAI US matched_1-1000.csv")  # Defines the path to the main training data CSV file.
    delimiter = ';'  # Specifies that the CSV file uses a semicolon to separate values.

    # Initialize the PatentClassifier with the data path and delimiter
    classifier = PatentClassifier(data_path, delimiter)

    # Load the main training data
    classifier.load_data()  # Reads and processes the main training data.

    # Add non-GenAI patents (anti-seed) to balance the dataset (comment out if not desired)
    n = 3146  # Number of non-GenAI patents to include from the anti-seed data.
    classifier.load_anti_seed(n)  # Loads and integrates the anti-seed data.

    # Preprocess data for classification and vectorization
    classifier.preprocess_data()  # Prepares the data by extracting features and converting text to numerical vectors.

    # Train and evaluate models
    classifier.train_and_evaluate()  # Trains each classifier using cross-validation and evaluates their performance.

    # Create and save plots of the performance metrics
    classifier.plot_all_metrics()  # Generates a bar chart comparing the performance of all classifiers.