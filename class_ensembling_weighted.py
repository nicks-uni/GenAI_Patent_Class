# -------------------------------------------------------------
# Import Required Packages
# -------------------------------------------------------------
# These lines import various tools and libraries that the script will use.
import \
    os  # Provides functions for interacting with the operating system, such as reading or writing files and creating directories.
import logging  # Enables logging of events that happen when some software runs, useful for debugging and monitoring.
import warnings  # Used to control warning messages generated by the code.
import \
    gc  # Provides functions to interact with the garbage collector, which helps manage memory by freeing up unused resources.
import random  # Provides functions to generate random numbers and perform random operations.

import \
    pandas as pd  # A powerful library for data manipulation and analysis, especially for working with tables of data.
import \
    numpy as np  # A library that supports large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays.
from tqdm import \
    tqdm  # Provides a progress bar for loops, making it easier to track the progress of long-running operations.
import \
    matplotlib.pyplot as plt  # A plotting library used for creating static, animated, and interactive visualizations.
import \
    seaborn as sns  # A library built on top of matplotlib that provides a higher-level interface for drawing attractive statistical graphics.

# Machine learning imports
from sklearn.model_selection import \
    StratifiedKFold  # A tool for splitting data into training and testing sets while maintaining the percentage of samples for each class.
from sklearn.metrics import (
    accuracy_score,  # Measures the proportion of correct predictions out of all predictions made.
    roc_auc_score,  # Measures the ability of the model to distinguish between classes.
    precision_score,  # Measures the accuracy of positive predictions.
    recall_score,  # Measures the ability of the model to find all positive instances.
    f1_score,  # The harmonic mean of precision and recall, providing a balance between the two.
    confusion_matrix,  # Summarizes the performance of a classification algorithm by displaying true vs. predicted labels.
)
from sklearn.svm import \
    SVC  # Support Vector Classifier, a type of machine learning model used for classification tasks.
from sklearn.ensemble import \
    RandomForestClassifier  # An ensemble model that builds multiple decision trees and merges their results for better accuracy.
from sklearn.feature_extraction.text import \
    TfidfVectorizer  # Converts a collection of raw documents to a matrix of TF-IDF features.

# Text processing imports
from nltk.tokenize import word_tokenize  # Splits sentences into words (tokens) using Natural Language Toolkit (NLTK).
from spacy.lang.en import STOP_WORDS  # A list of common English stop words (e.g., 'the', 'and') provided by spaCy.
import spacy  # A library for advanced Natural Language Processing in Python.

# For Large Language Models (LLMs)
from simpletransformers.classification import \
    ClassificationModel  # Simplifies the use of transformer models for classification tasks.
import torch  # A deep learning library that provides tensor computations and automatic differentiation.
import joblib  # Provides tools for saving and loading Python objects efficiently.

# Suppress warnings and set logging level to ERROR to reduce output clutter
warnings.filterwarnings("ignore")  # This line tells Python to ignore all warning messages, keeping the output clean.
logging.basicConfig(level=logging.ERROR)  # Sets the logging level to ERROR, so only error messages are logged.
transformers_logger = logging.getLogger("transformers")  # Gets the logger for the 'transformers' library.
transformers_logger.setLevel(logging.ERROR)  # Sets the 'transformers' logger to only show ERROR level messages.

# Check if CUDA (GPU acceleration) is available
use_cuda = torch.cuda.is_available()  # Checks if a CUDA-compatible GPU is available for faster computations.


# Set random seeds for reproducibility
def set_seed(seed=42):
    """
    Set the seed for random number generators to ensure reproducible results.

    Parameters:
    - seed (int): The seed value to use for random number generators.
    """
    random.seed(seed)  # Sets the seed for Python's built-in random module.
    np.random.seed(seed)  # Sets the seed for NumPy's random module.
    torch.manual_seed(seed)  # Sets the seed for PyTorch's CPU random number generator.
    if use_cuda:
        torch.cuda.manual_seed_all(seed)  # Sets the seed for all CUDA (GPU) devices.


set_seed()  # Calls the set_seed function with the default seed value of 42.


# Define a simple tokenizer function for text processing
def simple_tokenizer(text):
    """
    A simple tokenizer function that converts text to lowercase, splits it into words,
    and removes any non-alphanumeric tokens.

    Parameters:
    - text (str): The text to tokenize.

    Returns:
    - List[str]: A list of cleaned, alphanumeric tokens.
    """
    tokens = word_tokenize(text.lower())  # Converts text to lowercase and splits into words.
    return [token for token in tokens if token.isalnum()]  # Keeps only alphanumeric tokens.


# -------------------------------------------------------------
# Define the PatentEnsembleClassifier Class
# -------------------------------------------------------------
class PatentEnsembleClassifier:
    def __init__(self, data_path, anti_seed_path, delimiter):
        """
        Initialize the classifier with data paths and configuration settings.

        Parameters:
        - data_path (str): Path to the main training data CSV file.
        - anti_seed_path (str): Path to the anti-seed data CSV file.
        - delimiter (str): Character used to separate values in the CSV files (e.g., ',', ';').
        """
        # Paths to data files
        self.data_path = data_path  # Stores the path to the main training data.
        self.anti_seed_path = anti_seed_path  # Stores the path to the anti-seed data.
        self.delimiter = delimiter  # Stores the delimiter used in the CSV files.

        # Data storage variables
        self.data = None  # Placeholder for the combined dataset.
        self.IDs = None  # Placeholder for patent IDs.
        self.texts = None  # Placeholder for patent abstracts.
        self.labels = None  # Placeholder for labels indicating GenAI patents (1) or not (0).
        self.total_entries = None  # Placeholder for the total number of patents.
        self.total_ratio = None  # Placeholder for the ratio of GenAI to non-GenAI patents.
        self.results = []  # List to store performance results of each model.
        self.classified_values = []  # List to store individual classification results (actual vs. predicted).
        self.classified_values_p = []  # List to store predicted probabilities, if available.
        self.metrics = ["Accuracy", "AUC", "Precision", "Recall", "F1"]  # List of performance metrics to evaluate.
        self.results_table = None  # Placeholder for the table of results.

        # For Bag-of-Words (BOW) model
        self.vectorizer = None  # Placeholder for the TF-IDF vectorizer for Bag-of-Words.
        self.text_vectors_bow = None  # Placeholder for the numerical representation of the patent abstracts using BOW.

        # For embeddings model
        self.nlp = None  # Placeholder for the spaCy language model.
        self.text_vectors_embeddings = None  # Placeholder for the numerical representation of the patent abstracts using embeddings.

        # For LLMs
        self.use_cuda = use_cuda  # Indicates whether to use GPU acceleration for Large Language Models.

    def load_data(self):
        """
        Load and preprocess the training data from a CSV file.

        This function reads the CSV file containing patent data, processes it by creating a new label column
        indicating whether each patent is related to Generative AI (GenAI), and stores the processed data.
        """
        # Load the CSV file containing patent data
        self.data = pd.read_csv(self.data_path, delimiter=self.delimiter)  # Reads the CSV file into a pandas DataFrame.

        # Create a binary label: 1 if 'Finales Resultat' >= 1, else 0
        self.data["label_genai"] = (self.data["Finales Resultat"] >= 1).astype(
            int)  # Creates a new column 'label_genai' based on the 'Finales Resultat' column.

    def load_anti_seed(self, n):
        """
        Load and integrate additional data to balance the dataset.

        Parameters:
        - n (int): Number of anti-seed entries to include in the dataset.

        This function reads additional data containing non-GenAI patents to balance the dataset, ensuring
        that there are enough non-GenAI examples for the model to learn effectively.
        """
        # Load additional patent data to serve as 'non-AI' examples
        anti_seed = pd.read_csv(self.anti_seed_path,
                                delimiter=",")  # Reads the anti-seed CSV file into a pandas DataFrame.

        # Filter patents that do not contain AI content
        anti_seed = anti_seed[anti_seed["actual"] == 0]  # Filters the DataFrame to include only non-GenAI patents.

        # Limit the number of anti-seed patents to 'n'
        anti_seed = anti_seed[:n]  # Selects the first 'n' entries from the anti-seed DataFrame.

        # Assign the label 0 to these patents (non-AI)
        anti_seed["label_genai"] = 0  # Sets the 'label_genai' column to 0 for all anti-seed patents (non-GenAI).

        # Rename columns to match the main dataset
        anti_seed = anti_seed.rename(
            columns={"app number": "patent_id", "abstract": "patent_abstract"}
        )  # Renames columns to ensure consistency with the main training data.

        # Select relevant columns
        anti_seed = anti_seed[["patent_id", "patent_abstract", "label_genai"]]  # Keeps only the necessary columns.

        # Combine the main dataset with the anti-seed data
        self.data = pd.concat(
            [
                self.data[["patent_id", "patent_abstract", "label_genai"]],
                anti_seed,
            ],
            ignore_index=True,
        )  # Merges the main data with the anti-seed data to create a balanced dataset.

    def prepare_data(self):
        """
        Prepare data for text classification.

        This function extracts the necessary information from the combined dataset and calculates the distribution
        of labels to understand the balance between GenAI and non-GenAI patents.
        """
        # Extract IDs, texts (abstracts), and labels
        self.IDs = self.data["patent_id"].values  # Extracts patent IDs as a NumPy array.
        self.texts = self.data["patent_abstract"].tolist()  # Extracts patent abstracts as a list.
        self.labels = self.data["label_genai"].tolist()  # Extracts labels (1 or 0) as a list.

        # Calculate the percentage of each class
        label_counts = self.data["label_genai"].value_counts(
            normalize=True) * 100  # Calculates the percentage of each label.
        self.total_entries = len(self.data)  # Counts the total number of patents.
        self.total_ratio = f"{label_counts.get(1, 0):.0f}-{label_counts.get(0, 0):.0f}"  # Formats the ratio as "GenAI%-Non-GenAI%".

        # Output the distribution and total count
        print(f"Percentage of 'AI' patents: {label_counts.get(1, 0):.2f}%")  # Prints the percentage of GenAI patents.
        print(
            f"Percentage of 'non-AI' patents: {label_counts.get(0, 0):.2f}%")  # Prints the percentage of non-GenAI patents.
        print(f"AI/non-AI Ratio: {self.total_ratio}")  # Prints the ratio of GenAI to non-GenAI patents.
        print(f"Total number of patents: {self.total_entries}")  # Prints the total number of patents.

    def preprocess_bow(self):
        """
        Prepare data for the Bag-of-Words (BOW) model.

        This function converts the text data into numerical vectors based on word frequency using the TF-IDF method.
        It also saves the vectorizer for future use and prints the number of features extracted.
        """
        # Define parameters for the vectorizer
        MINDF = 10  # Minimum document frequency: the minimum number of documents a word must appear in to be included.
        MAXDF = 0.8  # Maximum document frequency: the maximum proportion of documents a word can appear in to be included.
        MAX_FEATURES = 1200  # Maximum number of features: limits the number of words to consider.
        NGRAM_RANGE = (1, 2)  # Use unigrams (single words) and bigrams (pairs of words).

        # Load stop words to exclude common words
        stop_words = list(STOP_WORDS)  # Retrieves a list of common English stop words from spaCy.

        # Initialize the TF-IDF vectorizer
        self.vectorizer = TfidfVectorizer(
            max_features=MAX_FEATURES,  # Limits the number of features to the top 'MAX_FEATURES'.
            max_df=MAXDF,  # Ignores words that appear in more than 'MAXDF' proportion of documents.
            min_df=MINDF,  # Ignores words that appear in fewer than 'MINDF' documents.
            stop_words=stop_words,  # Removes common stop words.
            ngram_range=NGRAM_RANGE,  # Considers both single words and pairs of words.
            tokenizer=simple_tokenizer,  # Uses the custom tokenizer defined above.
            token_pattern=None,  # Ensures compatibility with the custom tokenizer.
        )

        # Fit the vectorizer on the entire dataset
        self.vectorizer.fit(
            self.texts)  # Learns the vocabulary dictionary and inverse document frequency (IDF) from the texts.

        # Save the vectorizer for future use
        vectorizer_filename = 'Models/bow_vectorizer_final.joblib'  # Defines the filename for saving the vectorizer.
        joblib.dump(self.vectorizer, vectorizer_filename)  # Saves the vectorizer to a file.
        print(f"BOW vectorizer saved to {vectorizer_filename}")  # Confirms that the vectorizer has been saved.

        # Transform the texts into TF-IDF vectors
        self.text_vectors_bow = self.vectorizer.transform(
            self.texts)  # Converts the list of abstracts into a numerical matrix.

        # Output the number of features extracted
        self.feature_names = self.vectorizer.get_feature_names_out()  # Retrieves the names of the features (words) used in the vectorization.
        print(
            f"Number of extracted features: {len(self.feature_names)}")  # Prints the total number of features extracted.

    def preprocess_embeddings(self):
        """
        Prepare data for the embeddings model using spaCy.

        This function uses spaCy's word embeddings to convert each patent abstract into a numerical vector that captures its semantic meaning.
        """
        # Load the spaCy language model
        try:
            self.nlp = spacy.load("en_core_web_lg")  # Attempts to load the large English language model.
        except:
            import spacy.cli  # Imports the spaCy command-line interface.
            spacy.cli.download("en_core_web_lg")  # Downloads the large English language model if not already installed.
            self.nlp = spacy.load("en_core_web_lg")  # Loads the model after downloading.

        # Convert each abstract into a vector representation
        self.text_vectors_embeddings = np.array(
            [self.nlp(doc).vector for doc in tqdm(self.texts, desc="Computing embeddings")]
        )  # Uses spaCy to convert each patent abstract into a numerical vector based on word embeddings.

        # Output the dimension of the embeddings
        print(
            f"Embedding dimension: {self.text_vectors_embeddings.shape[1]}")  # Prints the size of each embedding vector.

    def balance_data(self, temp_X, temp_y):
        """
        Balance the training data by augmenting the minority class.

        Parameters:
        - temp_X (List): List of training data features.
        - temp_y (List): List of training data labels.

        This function duplicates examples from the minority class (GenAI patents) to balance the dataset,
        ensuring that both classes are equally represented during training.

        Returns:
        - Tuple[List, List]: The balanced lists of features and labels.
        """
        for _ in range(3):  # Repeats the balancing process three times to increase the minority class.
            for i in range(len(temp_y)):  # Iterates over each training example.
                if (temp_y[i] != 0) and (
                        np.mean(temp_y) < 0.5):  # Checks if the current label is GenAI and the current proportion is less than 50%.
                    temp_y.append(temp_y[i])  # Adds a GenAI label.
                    temp_X.append(temp_X[i])  # Adds the corresponding text vector.
        return temp_X, temp_y  # Returns the balanced lists.

    def train_and_predict_model(self, model, temp_X, temp_y, test_X):
        """
        Train the model and make predictions.

        Parameters:
        - model: The machine learning model to train.
        - temp_X (List or Array): Training data features.
        - temp_y (List): Training data labels.
        - test_X (List or Array): Testing data features.

        Returns:
        - Tuple[List, List]: Predicted labels and predicted probabilities.
        """
        model.fit(temp_X, temp_y)  # Fits the model to the training data.
        y_pred = model.predict(test_X)  # Predicts labels for the test set.
        y_pred_proba = model.predict_proba(test_X)[:, 1]  # Predicts probabilities for the positive class (GenAI).
        return y_pred, y_pred_proba  # Returns the predictions and probabilities.

    def train_and_predict_llm(self, model_type_name, model_name_or_path, train_df, test_texts):
        """
        Train an LLM model and make predictions.

        Parameters:
        - model_type_name (str): Type of the transformer model (e.g., 'bert', 'xlnet').
        - model_name_or_path (str): The specific pre-trained model to use.
        - train_df (DataFrame): DataFrame containing training texts and labels.
        - test_texts (List[str]): List of texts to predict.

        Returns:
        - Tuple[List, List]: Predicted labels and predicted probabilities.
        """
        model = ClassificationModel(
            model_type_name,  # Type of the transformer model.
            model_name_or_path,  # Pre-trained model name or path.
            use_cuda=self.use_cuda,  # Whether to use GPU acceleration.
            args={
                "num_train_epochs": 5,  # Number of training epochs.
                "overwrite_output_dir": True,  # Overwrites the output directory if it exists.
                "use_early_stopping": False,  # Disables early stopping.
                "train_batch_size": 50,  # Batch size for training.
                "do_lower_case": True,  # Converts all characters to lowercase.
                "silent": False,  # Enables verbose output during training.
                "no_cache": True,  # Disables caching.
                "no_save": True,  # Disables saving the model after training.
            },
        )
        model.train_model(train_df)  # Trains the model using the training DataFrame.
        predictions, raw_outputs = model.predict(list(test_texts))  # Predicts labels for the test set.
        y_pred = predictions  # Predicted labels.
        y_pred_proba = torch.softmax(torch.tensor(raw_outputs), dim=1)[:,
                       1].tolist()  # Converts raw outputs to probabilities.
        del model  # Deletes the model instance to free up memory.
        gc.collect()  # Collects garbage to free up memory.
        torch.cuda.empty_cache()  # Frees up unused memory in the GPU.
        return y_pred, y_pred_proba  # Returns the predictions and probabilities.

    def collect_predictions(self, predictions_dict, name, test_labels, y_pred, test_IDs, y_pred_proba):
        """
        Collect predictions and probabilities for a given model.

        Parameters:
        - predictions_dict (dict): Dictionary to store predictions.
        - name (str): Name of the model.
        - test_labels (List): Actual labels for the test set.
        - y_pred (List): Predicted labels from the model.
        - test_IDs (List): Patent IDs for the test set.
        - y_pred_proba (List): Predicted probabilities from the model.
        """
        predictions_dict[name]["y_actual"].extend(test_labels)  # Appends actual labels to the dictionary.
        predictions_dict[name]["y_predicted"].extend(y_pred)  # Appends predicted labels to the dictionary.
        predictions_dict[name]["id_s"].extend(test_IDs)  # Appends patent IDs to the dictionary.
        predictions_dict[name]["y_predicted_p"].extend(
            y_pred_proba)  # Appends predicted probabilities to the dictionary.

    def train_and_evaluate_models(self):
        """
        Train and evaluate all models using cross-validation.

        This function sets up different machine learning models, trains them using cross-validation,
        evaluates their performance using various metrics, and stores the results for comparison.
        """
        NUM_OF_SPLITS = 5  # Number of folds for cross-validation.
        Reweight = True  # Option to balance the training data by duplicating minority class examples.

        # Convert labels and IDs to numpy arrays for efficient processing.
        Y = np.array(self.labels)  # Array of labels (1 for GenAI, 0 for non-GenAI).
        IDs = np.array(self.IDs)  # Array of patent IDs.

        # Prepare data arrays.
        Texts = np.array(self.texts)  # Array of patent abstracts.
        Abstract_Vectors_BOW = self.text_vectors_bow  # Numerical representation using Bag-of-Words.
        Abstract_Vectors_Embeddings = self.text_vectors_embeddings  # Numerical representation using embeddings.

        # Initialize Stratified K-Fold cross-validator.
        KFoldSplitter = StratifiedKFold(n_splits=NUM_OF_SPLITS, shuffle=True,
                                        random_state=1)  # Ensures each fold has the same class distribution.

        # Prepare to store predictions from different models.
        predictions_dict = {}  # Dictionary to store actual and predicted values for each model.

        # Define the models to train.
        models_to_train = [
            # Bag-of-Words model
            {
                "name": "Random Forest (BOW)",  # Name of the model.
                "type": "BOW",  # Type indicating it's a Bag-of-Words model.
                "model": RandomForestClassifier(n_estimators=1000),
                # Initializes the Random Forest classifier with 1000 trees.
            },
            # Embeddings model
            {
                "name": "SVC (Embeddings)",  # Name of the model.
                "type": "Embeddings",  # Type indicating it's an embeddings-based model.
                "model": SVC(probability=True, class_weight='balanced'),
                # Initializes the Support Vector Classifier with probability estimates and balanced class weights.
            },
            # Large Language Models (LLMs)
            {
                "name": "SciBERT",  # Name of the model.
                "type": "LLM",  # Type indicating it's a Large Language Model.
                "model_type": "bert",  # Specifies the transformer model type.
                "model_name_or_path": "allenai/scibert_scivocab_uncased",  # Path to the pre-trained SciBERT model.
                "model": None,  # Placeholder for the trained model.
            },
            {
                "name": "XLNet",  # Name of the model.
                "type": "LLM",  # Type indicating it's a Large Language Model.
                "model_type": "xlnet",  # Specifies the transformer model type.
                "model_name_or_path": "xlnet-base-cased",  # Path to the pre-trained XLNet model.
                "model": None,  # Placeholder for the trained model.
            },
        ]

        # Cross-validation loop
        for train_idx, test_idx in tqdm(KFoldSplitter.split(Texts, Y), desc="Cross-Validating"):
            # Split data into training and testing sets based on the current fold.
            train_texts, test_texts = Texts[train_idx], Texts[test_idx]  # Training and testing patent abstracts.
            train_labels, test_labels = Y[train_idx], Y[test_idx]  # Training and testing labels.
            train_IDs, test_IDs = IDs[train_idx], IDs[test_idx]  # Training and testing patent IDs.

            # For BOW models, fit a new vectorizer within the fold.
            vectorizer = TfidfVectorizer(
                max_features=1200,  # Maximum number of features.
                max_df=0.8,  # Maximum document frequency.
                min_df=10,  # Minimum document frequency.
                stop_words=list(STOP_WORDS),  # List of stop words to remove.
                ngram_range=(1, 2),  # Range of n-grams to include.
                tokenizer=simple_tokenizer,  # Custom tokenizer function.
                token_pattern=None,  # Ensures compatibility with the custom tokenizer.
            )
            train_vectors_bow = vectorizer.fit_transform(
                train_texts)  # Fits the vectorizer on training texts and transforms them.
            test_vectors_bow = vectorizer.transform(test_texts)  # Transforms testing texts using the fitted vectorizer.

            # For Embeddings models, select the corresponding training and testing vectors.
            train_vectors_embeddings = Abstract_Vectors_Embeddings[train_idx]  # Training embeddings.
            test_vectors_embeddings = Abstract_Vectors_Embeddings[test_idx]  # Testing embeddings.

            # Prepare training DataFrame for LLMs.
            train_df = pd.DataFrame(
                {"text": train_texts, "labels": train_labels})  # Creates a DataFrame with training texts and labels.

            # Train each model.
            for model_info in models_to_train:
                name = model_info["name"]  # Model name.
                model_type = model_info["type"]  # Type of the model (BOW, Embeddings, LLM).

                # Initialize the predictions dictionary for the model if not already present.
                if name not in predictions_dict:
                    predictions_dict[name] = {"y_actual": [], "y_predicted": [], "id_s": [], "y_predicted_p": []}

                if model_type == "BOW":
                    # Handle Bag-of-Words model.
                    model = model_info["model"]  # Retrieves the model instance.
                    temp_y = list(train_labels)  # Creates a temporary list of training labels.
                    temp_X = train_vectors_bow.todense().tolist()  # Converts training vectors to a dense list for compatibility.

                    if Reweight:
                        # Balance the training data by duplicating minority class examples.
                        temp_X, temp_y = self.balance_data(temp_X, temp_y)

                    test_X = np.asarray(test_vectors_bow.todense())  # Converts test vectors to a NumPy array.

                    # Train the model and make predictions.
                    y_pred, y_pred_proba = self.train_and_predict_model(model, temp_X, temp_y, test_X)

                elif model_type == "Embeddings":
                    # Handle Embeddings model.
                    model = model_info["model"]  # Retrieves the model instance.
                    temp_y = list(train_labels)  # Creates a temporary list of training labels.
                    temp_X = list(train_vectors_embeddings)  # Creates a temporary list of training embeddings.
                    test_X = test_vectors_embeddings  # Sets the testing embeddings.

                    if Reweight:
                        # Balance the training data by duplicating minority class examples.
                        temp_X, temp_y = self.balance_data(temp_X, temp_y)

                    temp_X = np.array(temp_X)  # Converts the list back to a NumPy array.

                    # Train the model and make predictions.
                    y_pred, y_pred_proba = self.train_and_predict_model(model, temp_X, temp_y, test_X)

                elif model_type == "LLM":
                    # Handle Large Language Models (LLMs).
                    y_pred, y_pred_proba = self.train_and_predict_llm(
                        model_info["model_type"],  # Type of the transformer model.
                        model_info["model_name_or_path"],  # Path to the pre-trained model.
                        train_df,  # Training DataFrame.
                        test_texts,  # List of texts to predict.
                    )

                else:
                    continue  # Skips if the model type is unknown.

                # Collect predictions.
                self.collect_predictions(predictions_dict, name, test_labels, y_pred, test_IDs, y_pred_proba)

        # After cross-validation, evaluate each model.
        for model_info in models_to_train:
            name = model_info["name"]  # Model name.
            y_actual = predictions_dict[name]["y_actual"]  # Actual labels.
            y_predicted = predictions_dict[name]["y_predicted"]  # Predicted labels.
            id_s = predictions_dict[name]["id_s"]  # Patent IDs.
            y_predicted_p = predictions_dict[name]["y_predicted_p"]  # Predicted probabilities.

            # Evaluate metrics.
            Share = np.round(np.mean(y_predicted), 3)  # Calculates the average share of patents classified as GenAI.
            Accuracy = accuracy_score(y_actual, y_predicted)  # Overall accuracy of the model.
            if len(set(y_actual)) > 1 and len(set(y_predicted_p)) > 1:
                ROC = roc_auc_score(y_actual,
                                    y_predicted_p)  # Measures the model's ability to distinguish between classes.
            else:
                ROC = None  # Sets ROC to None if it's not applicable.
            Precision = precision_score(y_actual, y_predicted, zero_division=0)  # Accuracy of positive predictions.
            Recall = recall_score(y_actual, y_predicted, zero_division=0)  # Ability to find all positive instances.
            F1 = f1_score(y_actual, y_predicted, zero_division=0)  # Harmonic mean of precision and recall.
            CM = confusion_matrix(y_actual, y_predicted)  # Confusion matrix to understand the types of errors.

            # Handle confusion matrix.
            try:
                TN, FP, FN, TP = CM.ravel()  # Extracts True Negatives, False Positives, False Negatives, and True Positives.
            except ValueError:
                TN = FP = FN = TP = None  # Sets counts to None if there's an error.

            # Add metrics to results.
            self.results.append(
                [
                    name,  # Model name.
                    Share,  # Share of GenAI classifications.
                    TP,  # True Positives.
                    FN,  # False Negatives.
                    FP,  # False Positives.
                    TN,  # True Negatives.
                    np.round(Accuracy, 3),  # Rounded Accuracy.
                    np.round(ROC, 3) if ROC is not None else None,  # Rounded ROC or None.
                    np.round(Precision, 3),  # Rounded Precision.
                    np.round(Recall, 3),  # Rounded Recall.
                    np.round(F1, 3),  # Rounded F1 Score.
                ]
            )

            # Save classification results.
            self.classified_values.append(
                list(zip([name] * len(id_s), id_s, y_actual, y_predicted))
            )  # Stores the results for each patent.

            # Save predicted probabilities.
            self.classified_values_p.append(
                list(zip([name] * len(id_s), id_s, y_actual, y_predicted_p))
            )  # Stores the predicted probabilities.

        # After cross-validation, save the trained models.
        for model_info in models_to_train:
            name = model_info["name"]  # Model name.
            model_type = model_info["type"]  # Type of model (BOW, Embeddings, LLM).
            model = model_info["model"]  # Trained model instance.

            if model_type == "BOW":
                # Save the model and vectorizer.
                model_filename = f'Models/{name.replace(" ", "_")}_model_final.joblib'  # Defines the filename for saving the model.
                vectorizer_filename = 'Models/bow_vectorizer_final.joblib'  # Filename for the vectorizer.
                joblib.dump(model, model_filename)  # Saves the BOW model to a file.
                joblib.dump(self.vectorizer, vectorizer_filename)  # Saves the BOW vectorizer to a file.
                print(f"{name} model and vectorizer saved.")  # Confirms saving.

            elif model_type == "Embeddings":
                # Save the model.
                model_filename = f'Models/{name.replace(" ", "_")}_model_final.joblib'  # Defines the filename for saving the model.
                joblib.dump(model, model_filename)  # Saves the embeddings model to a file.
                print(f"{name} model saved.")  # Confirms saving.

            elif model_type == "LLM":
                # We didn't keep the model instances to save memory; if needed, retrain and save here.
                print(f"{name} model not saved to conserve resources.")  # Notifies that LLM models are not saved.

    def consolidate_predictions(self):
        """
        Consolidate predictions from all models into a single DataFrame.

        This function merges the individual predictions from each model based on patent IDs,
        creating a comprehensive DataFrame that includes predictions from all models.

        Returns:
        - DataFrame: A DataFrame containing actual labels and predictions from all models.
        """
        Final = pd.DataFrame()  # Initializes an empty DataFrame to store consolidated predictions.
        for i in range(len(self.classified_values)):
            Temp = pd.DataFrame(
                self.classified_values[i], columns=["Model", "id", "Actual", "Predicted"]
            )  # Creates a temporary DataFrame for the current model's predictions.
            name = Temp.iloc[0]["Model"]  # Retrieves the model name from the first row.
            if i == 0:
                Temp = Temp[["id", "Actual", "Predicted"]]  # Selects relevant columns.
                Temp.columns = ["id", "Actual", name]  # Renames columns to include the model name.
                Final = Temp  # Initializes the Final DataFrame with the first model's results.
            else:
                Temp = Temp[["id", "Predicted"]]  # Selects relevant columns.
                Temp.columns = ["id", name]  # Renames columns to include the model name.
                Final = Final.merge(Temp, on="id")  # Merges with the Final DataFrame based on 'id'.
        return Final  # Returns the consolidated DataFrame.

    def consolidate_probabilities(self, Final):
        """
        Consolidate predicted probabilities from all models into the DataFrame.

        Parameters:
        - Final (DataFrame): The consolidated predictions DataFrame.

        This function merges the predicted probabilities from each model into the Final DataFrame.

        Returns:
        - DataFrame: The updated Final DataFrame with predicted probabilities.
        """
        for i in range(len(self.classified_values_p)):
            Temp_p = pd.DataFrame(
                self.classified_values_p[i], columns=["Model", "id", "Actual", "Predicted_Prob"]
            )  # Creates a temporary DataFrame for the current model's predicted probabilities.
            name = Temp_p.iloc[0]["Model"]  # Retrieves the model name from the first row.
            Temp_p = Temp_p[["id", "Predicted_Prob"]]  # Selects relevant columns.
            Temp_p.columns = ["id", f"{name}_prob"]  # Renames columns to include the model name.
            Final = Final.merge(Temp_p, on="id")  # Merges with the Final DataFrame based on 'id'.
        return Final  # Returns the updated Final DataFrame with predicted probabilities.

    def output_results(self):
        """
        Output the classification results, perform weighted ensembling, and save the results.

        This function converts the collected results into a structured format, saves them as CSV files,
        and displays them for review. It also creates ensemble predictions using weighted averaging based on model performance.
        """
        # Convert the results list to a DataFrame.
        self.results_table = pd.DataFrame(
            self.results,
            columns=[
                "Name",  # Model name.
                "Share",  # Share of GenAI classifications.
                "True-Positives",  # Number of correct GenAI predictions.
                "False-Negatives",  # Number of GenAI patents incorrectly predicted as non-GenAI.
                "False-Positives",  # Number of non-GenAI patents incorrectly predicted as GenAI.
                "True-Negatives",  # Number of correct non-GenAI predictions.
                "Accuracy",  # Overall accuracy of the model.
                "AUC",  # Area Under the ROC Curve.
                "Precision",  # Accuracy of positive predictions.
                "Recall",  # Ability to find all positive instances.
                "F1",  # Harmonic mean of precision and recall.
            ],
        )

        # Add a new column 'Type' to distinguish individual models and the ensemble.
        self.results_table["Type"] = "Individual"  # Specifies that the metrics are for individual models.

        # Rearrange columns for readability.
        self.results_table = self.results_table[
            [
                "Name",
                "Type",
                "Share",
                "True-Positives",
                "False-Negatives",
                "False-Positives",
                "True-Negatives",
                "Accuracy",
                "AUC",
                "Precision",
                "Recall",
                "F1",
            ]
        ]  # Orders the columns in a logical sequence.

        # Save the individual model results to a CSV file.
        output_path = f"Output/Classification_Model_GenAI_Performance_{self.total_entries}_{self.total_ratio}.csv"  # Defines the filename for saving the results.
        self.results_table.sort_values("Accuracy", ascending=False).to_csv(
            output_path, index=False
        )  # Saves the performance metrics to a CSV file for further analysis.
        print(f"Results saved to {output_path}")  # Confirms that the results have been saved.

        # Display the results.
        print(self.results_table.sort_values("Accuracy",
                                             ascending=False))  # Prints the sorted results table to the console.

        # Consolidate predictions and probabilities.
        Final = self.consolidate_predictions()  # Merges individual model predictions.
        Final = self.consolidate_probabilities(Final)  # Merges individual model predicted probabilities.

        # Save the consolidated predictions to a CSV file.
        final_output_path = (
            f"Output/Classification_GenAI_Results_{self.total_entries}_{self.total_ratio}.csv"
        )  # Defines the filename for saving the detailed classification results.
        Final.to_csv(final_output_path, index=False)  # Saves the detailed classification results.
        print(f"Classification results saved to {final_output_path}")  # Confirms saving.

        # Now, create ensemble predictions using weighted averaging.
        # Assign weights based on model performance (e.g., Accuracy).
        weight_metric = "Accuracy"  # You can change this to use another metric.
        weights = {}  # Dictionary to store weights for each model.
        for idx, row in self.results_table.iterrows():
            if row["Name"] == "Ensemble":
                continue  # Skip if Ensemble already exists.
            weights[row["Name"]] = row[weight_metric]  # Assign weight based on the chosen metric.

        # Normalize weights to sum to 1.
        total_weight = sum(weights.values())  # Calculates the total weight.
        normalized_weights = {k: v / total_weight for k, v in weights.items()}  # Normalizes weights.
        print(
            f"Normalized Weights for Ensembling based on {weight_metric}: {normalized_weights}")  # Prints the normalized weights.

        # Calculate weighted probabilities.
        Final["Weighted_Predicted_Prob"] = 0.0  # Initializes a new column for weighted probabilities.
        for model_name, weight in normalized_weights.items():
            prob_col = f"{model_name}_prob"  # Defines the column name for the model's predicted probabilities.
            if prob_col in Final.columns:
                # Replace NaN with 0.0 to ensure accurate calculations.
                Final[prob_col].fillna(0.0, inplace=True)  # Replaces any missing probabilities with 0.0.
                Final["Weighted_Predicted_Prob"] += weight * Final[prob_col]  # Adds the weighted probability.
            else:
                print(
                    f"Probability column {prob_col} not found in Final DataFrame.")  # Notifies if a probability column is missing.

        # Define ensemble prediction based on weighted probabilities.
        Final["Ensemble_Predicted"] = (Final["Weighted_Predicted_Prob"] >= 0.5).astype(
            int)  # Assigns a label of 1 if the weighted probability is >= 0.5, else 0.

        # Evaluate ensemble predictions.
        y_actual = Final["Actual"]  # Actual labels.
        y_predicted = Final["Ensemble_Predicted"]  # Ensemble predicted labels.
        y_predicted_proba = Final["Weighted_Predicted_Prob"]  # Ensemble predicted probabilities.

        # Evaluate metrics for the ensemble.
        Share = np.round(np.mean(y_predicted), 3)  # Calculates the average share of patents classified as GenAI.
        Accuracy = accuracy_score(y_actual, y_predicted)  # Overall accuracy of the ensemble model.
        if len(set(y_actual)) > 1 and len(set(y_predicted_proba)) > 1:
            ROC = roc_auc_score(y_actual,
                                y_predicted_proba)  # Measures the ensemble model's ability to distinguish between classes.
        else:
            ROC = None  # Sets ROC to None if it's not applicable.
        Precision = precision_score(y_actual, y_predicted, zero_division=0)  # Accuracy of positive predictions.
        Recall = recall_score(y_actual, y_predicted, zero_division=0)  # Ability to find all positive instances.
        F1 = f1_score(y_actual, y_predicted, zero_division=0)  # Harmonic mean of precision and recall.
        CM = confusion_matrix(y_actual, y_predicted)  # Confusion matrix for the ensemble model.

        # Handle confusion matrix.
        try:
            TN, FP, FN, TP = CM.ravel()  # Extracts True Negatives, False Positives, False Negatives, and True Positives.
        except ValueError:
            TN = FP = FN = TP = None  # Sets counts to None if there's an error.

        # Add ensemble metrics to results.
        self.results.append(
            [
                "Ensemble",  # Name of the ensemble model.
                Share,  # Share of GenAI classifications.
                TP,  # True Positives.
                FN,  # False Negatives.
                FP,  # False Positives.
                TN,  # True Negatives.
                np.round(Accuracy, 3),  # Rounded Accuracy.
                np.round(ROC, 3) if ROC is not None else None,  # Rounded ROC or None.
                np.round(Precision, 3),  # Rounded Precision.
                np.round(Recall, 3),  # Rounded Recall.
                np.round(F1, 3),  # Rounded F1 Score.
            ]
        )

        # Update results_table with the ensemble metrics.
        self.results_table = pd.DataFrame(
            self.results,
            columns=[
                "Name",  # Model name.
                "Share",  # Share of GenAI classifications.
                "True-Positives",  # Number of correct GenAI predictions.
                "False-Negatives",  # Number of GenAI patents incorrectly predicted as non-GenAI.
                "False-Positives",  # Number of non-GenAI patents incorrectly predicted as GenAI.
                "True-Negatives",  # Number of correct non-GenAI predictions.
                "Accuracy",  # Overall accuracy of the model.
                "AUC",  # Area Under the ROC Curve.
                "Precision",  # Accuracy of positive predictions.
                "Recall",  # Ability to find all positive instances.
                "F1",  # Harmonic mean of precision and recall.
            ],
        )
        self.results_table["Type"] = "Individual"  # Specifies that the metrics are for individual models.
        self.results_table.loc[self.results_table[
                                   "Name"] == "Ensemble", "Type"] = "Ensemble"  # Changes the type to 'Ensemble' for the ensemble model.

        # Rearrange columns for readability.
        self.results_table = self.results_table[
            [
                "Name",
                "Type",
                "Share",
                "True-Positives",
                "False-Negatives",
                "False-Positives",
                "True-Negatives",
                "Accuracy",
                "AUC",
                "Precision",
                "Recall",
                "F1",
            ]
        ]  # Orders the columns in a logical sequence.

        # Save updated results table to a CSV file.
        output_path = f"Output/Classification_Model_GenAI_Performance_{self.total_entries}_{self.total_ratio}.csv"  # Defines the filename for saving the updated results.
        self.results_table.sort_values("Accuracy", ascending=False).to_csv(
            output_path, index=False
        )  # Saves the updated performance metrics to a CSV file.
        print(f"Updated Results saved to {output_path}")  # Confirms that the updated results have been saved.

        # Display the updated results.
        print(self.results_table.sort_values("Accuracy",
                                             ascending=False))  # Prints the sorted results table to the console.

        # Save the final DataFrame with ensemble predictions.
        final_output_path = f"Output/Classification_GenAI_Results_with_Ensemble_{self.total_entries}_{self.total_ratio}.csv"  # Defines the filename for saving the final classification results with ensemble.
        Final.to_csv(final_output_path,
                     index=False)  # Saves the final classification results with ensemble predictions.
        print(f"Classification results with ensemble saved to {final_output_path}")  # Confirms saving.

    def plot_all_metrics(self):
        """
        Create and save a grouped bar chart for all metrics.

        This visualization helps in comparing the performance metrics of different models side by side.
        """
        df_plot = self.results_table[["Name"] + self.metrics]  # Selects the 'Name' and metric columns for plotting.

        num_models = len(df_plot["Name"])  # Counts the number of models.
        num_metrics = len(self.metrics)  # Counts the number of metrics.

        ind = np.arange(num_models)  # The x locations for the groups.
        total_width = 0.8  # Total width for all bars in a group.
        width = total_width / num_metrics  # Width of each individual bar.

        fig, ax = plt.subplots(figsize=(12, 6))  # Creates a figure and a set of subplots with a specified size.

        for i, metric in enumerate(self.metrics):
            # Positioning of bars within each group.
            offset = (i - num_metrics / 2) * width + width / 2  # Calculates the offset for each metric.
            positions = ind + offset  # Calculates the positions for the bars.
            bars = ax.bar(positions, df_plot[metric], width, label=metric)  # Creates a bar for each metric.

            # Adding metric values on the bars for clarity.
            for bar in bars:
                height = bar.get_height()  # Gets the height of the bar.
                ax.annotate(
                    f"{height:.2f}",  # Formats the height to two decimal places.
                    xy=(bar.get_x() + bar.get_width() / 2, height),  # Position for the annotation.
                    xytext=(0, 3),  # Vertical offset in points.
                    textcoords="offset points",  # Specifies that the text position is offset by points.
                    ha="center",  # Horizontally centers the text.
                    va="bottom",  # Vertically aligns the text to the bottom of the annotation point.
                    fontsize=8,  # Sets the font size of the annotation.
                )  # Places the annotation above the bar.

        ax.set_xlabel("Model Name")  # Labels the x-axis.
        ax.set_ylabel("Scores")  # Labels the y-axis.
        ax.set_title(
            f"Comparison of Model Performance ({self.total_entries} patents, ratio: {self.total_ratio})"
        )  # Sets a descriptive title that includes the number of patents and the ratio.
        ax.set_xticks(ind)  # Sets the positions of the x-axis ticks.
        ax.set_xticklabels(df_plot["Name"], rotation=45,
                           ha="right")  # Labels the x-axis ticks with model names, rotated for better readability.
        ax.legend()  # Adds a legend to differentiate the metrics.

        plt.tight_layout()  # Adjusts the padding between and around subplots to prevent overlapping elements.
        plt.savefig(
            f"Figures/model_performance_grouped_bar_{self.total_entries}_{self.total_ratio}.png",
            dpi=300,
        )  # Saves the figure as a high-resolution PNG file.
        plt.show()  # Displays the plot to the user.


# -------------------------------------------------------------
# Main Execution
# -------------------------------------------------------------
# The following code runs when the script is executed directly.
# To run the code, execute the following command in the terminal:
# python class_ensembling_weighted.py

if __name__ == "__main__":
    # Ensure necessary directories exist.
    if not os.path.exists("Figures"):
        os.makedirs("Figures")  # Creates the 'Figures' directory to store plots.
    if not os.path.exists("Output"):
        os.makedirs("Output")  # Creates the 'Output' directory to store result CSV files.
    if not os.path.exists("Models"):
        os.makedirs("Models")  # Creates the 'Models' directory to store trained models and vectorizers.

    # Paths to data files.
    data_path = os.path.join(
        "Training Data", "20240819_WIPO Patents GenAI US matched_1-1000.csv"
    )  # Defines the path to the main training data CSV file.
    delimiter = ";"  # Specifies that the CSV file uses a semicolon to separate values.

    anti_seed_path = os.path.join("Training Data",
                                  "4K Patents - AI 20p.csv")  # Defines the path to the anti-seed data CSV file.

    # Initialize the classifier.
    classifier = PatentEnsembleClassifier(data_path, anti_seed_path,
                                          delimiter)  # Creates an instance of the PatentEnsembleClassifier.

    # Load and prepare data.
    classifier.load_data()  # Reads and processes the main training data.
    classifier.load_anti_seed(n=3146)  # Loads and integrates the anti-seed data with a specified number of entries.
    classifier.prepare_data()  # Prepares the data by extracting features and calculating label distributions.

    # Preprocess data for different models.
    classifier.preprocess_bow()  # Prepares data for the Bag-of-Words model.
    classifier.preprocess_embeddings()  # Prepares data for the embeddings model.

    # Train and evaluate models.
    classifier.train_and_evaluate_models()  # Trains each classifier using cross-validation and evaluates their performance.

    # Output results and plots.
    classifier.output_results()  # Outputs and saves the classification results.
    classifier.plot_all_metrics()  # Generates a bar chart comparing the performance of all classifiers.